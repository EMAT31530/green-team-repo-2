{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code attempts to tune the XGBoosting results with different parameters.  \n",
    "This code uses the native API of XGboosting, rather than the scikit-learn API of XGboost. The native API has the advantage of automatically finding the best number of boosting rounds, has a built in cross validation feature and allows for custom objective functions. The native API uses Dmatrices which contain the features and the target variable (in this case the carbon intensity). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing modules for the implementation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>Food Group</th>\n",
       "      <th>Calories</th>\n",
       "      <th>Fat (g)</th>\n",
       "      <th>Protein (g)</th>\n",
       "      <th>Carbohydrate (g)</th>\n",
       "      <th>Sugars (g)</th>\n",
       "      <th>Fiber (g)</th>\n",
       "      <th>Saturated Fats (g)</th>\n",
       "      <th>Calcium (mg)</th>\n",
       "      <th>...</th>\n",
       "      <th>Lutein + Zeaxanthin (mcg)</th>\n",
       "      <th>Fatty acids, total monounsaturated (mg)</th>\n",
       "      <th>Fatty acids, total polyunsaturated (mg)</th>\n",
       "      <th>20:5 n-3 (EPA) (mg)</th>\n",
       "      <th>22:5 n-3 (DPA) (mg)</th>\n",
       "      <th>22:6 n-3 (DHA) (mg)</th>\n",
       "      <th>Caffeine (mg)</th>\n",
       "      <th>Theobromine (mg)</th>\n",
       "      <th>Price per Weight (Â£/100Gram)</th>\n",
       "      <th>GHG(kgco2eq/100g)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cranberry Juice Cocktail Frozen Concentrate Pr...</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>11.81</td>\n",
       "      <td>9.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>0.1214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Broccoli</td>\n",
       "      <td>Vegetables</td>\n",
       "      <td>34</td>\n",
       "      <td>0.37</td>\n",
       "      <td>2.82</td>\n",
       "      <td>6.64</td>\n",
       "      <td>1.70</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.114</td>\n",
       "      <td>47</td>\n",
       "      <td>...</td>\n",
       "      <td>1403.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.130667</td>\n",
       "      <td>0.0437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rum</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>231</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>0.1585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Orange Juice Light No Pulp</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.21</td>\n",
       "      <td>5.42</td>\n",
       "      <td>4.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069000</td>\n",
       "      <td>0.0317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Veggie Burgers</td>\n",
       "      <td>Beans and Lentils</td>\n",
       "      <td>177</td>\n",
       "      <td>6.30</td>\n",
       "      <td>15.70</td>\n",
       "      <td>14.27</td>\n",
       "      <td>1.07</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.440</td>\n",
       "      <td>136</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1778.0</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.2871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>Chicken Ground</td>\n",
       "      <td>Meats</td>\n",
       "      <td>201</td>\n",
       "      <td>10.31</td>\n",
       "      <td>27.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.647</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3429.0</td>\n",
       "      <td>2893.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.6092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>Chicken Broilers Or Fryers Wing Meat Only Cook...</td>\n",
       "      <td>Meats</td>\n",
       "      <td>197</td>\n",
       "      <td>9.53</td>\n",
       "      <td>27.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.223</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3766.0</td>\n",
       "      <td>1323.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.6092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>Bread White Wheat</td>\n",
       "      <td>Baked Foods</td>\n",
       "      <td>238</td>\n",
       "      <td>2.15</td>\n",
       "      <td>10.66</td>\n",
       "      <td>43.91</td>\n",
       "      <td>5.00</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.630</td>\n",
       "      <td>684</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>973.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.118750</td>\n",
       "      <td>0.1441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>Alcoholic Beverage Daiquiri Prepared-From-Recipe</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>186</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>6.94</td>\n",
       "      <td>5.58</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.006</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.1585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>Pork Ground Or Patty Cooked</td>\n",
       "      <td>Meats</td>\n",
       "      <td>295</td>\n",
       "      <td>20.60</td>\n",
       "      <td>25.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.656</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9173.0</td>\n",
       "      <td>1854.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.7282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>832 rows Ã 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  name         Food Group  \\\n",
       "0    Cranberry Juice Cocktail Frozen Concentrate Pr...          Beverages   \n",
       "1                                             Broccoli         Vegetables   \n",
       "2                                                  Rum          Beverages   \n",
       "3                           Orange Juice Light No Pulp          Beverages   \n",
       "4                                       Veggie Burgers  Beans and Lentils   \n",
       "..                                                 ...                ...   \n",
       "827                                     Chicken Ground              Meats   \n",
       "828  Chicken Broilers Or Fryers Wing Meat Only Cook...              Meats   \n",
       "829                                  Bread White Wheat        Baked Foods   \n",
       "830   Alcoholic Beverage Daiquiri Prepared-From-Recipe          Beverages   \n",
       "831                        Pork Ground Or Patty Cooked              Meats   \n",
       "\n",
       "     Calories  Fat (g)  Protein (g)  Carbohydrate (g)  Sugars (g)  Fiber (g)  \\\n",
       "0          47     0.00         0.01             11.81        9.76        0.0   \n",
       "1          34     0.37         2.82              6.64        1.70        2.6   \n",
       "2         231     0.00         0.00              0.00        0.00        0.0   \n",
       "3          21     0.00         0.21              5.42        4.17        0.0   \n",
       "4         177     6.30        15.70             14.27        1.07        4.9   \n",
       "..        ...      ...          ...               ...         ...        ...   \n",
       "827       201    10.31        27.14              0.00        0.00        0.0   \n",
       "828       197     9.53        27.69              0.00        0.00        0.0   \n",
       "829       238     2.15        10.66             43.91        5.00        9.2   \n",
       "830       186     0.06         0.06              6.94        5.58        0.1   \n",
       "831       295    20.60        25.48              0.00        0.00        0.0   \n",
       "\n",
       "     Saturated Fats (g)  Calcium (mg)  ...  Lutein + Zeaxanthin (mcg)  \\\n",
       "0                 0.000             5  ...                        0.0   \n",
       "1                 0.114            47  ...                     1403.0   \n",
       "2                 0.000             0  ...                        0.0   \n",
       "3                 0.000             0  ...                       47.0   \n",
       "4                 1.440           136  ...                        0.0   \n",
       "..                  ...           ...  ...                        ...   \n",
       "827               2.647            28  ...                        0.0   \n",
       "828               2.223            32  ...                        0.0   \n",
       "829               0.630           684  ...                       25.0   \n",
       "830               0.006             3  ...                        0.0   \n",
       "831               7.656            22  ...                        0.0   \n",
       "\n",
       "     Fatty acids, total monounsaturated (mg)  \\\n",
       "0                                        0.0   \n",
       "1                                       31.0   \n",
       "2                                        0.0   \n",
       "3                                        0.0   \n",
       "4                                     1778.0   \n",
       "..                                       ...   \n",
       "827                                   3429.0   \n",
       "828                                   3766.0   \n",
       "829                                    393.0   \n",
       "830                                      6.0   \n",
       "831                                   9173.0   \n",
       "\n",
       "     Fatty acids, total polyunsaturated (mg)  20:5 n-3 (EPA) (mg)  \\\n",
       "0                                        0.0                  0.0   \n",
       "1                                      112.0                  0.0   \n",
       "2                                        0.0                  0.0   \n",
       "3                                        0.0                  0.0   \n",
       "4                                     2023.0                  0.0   \n",
       "..                                       ...                  ...   \n",
       "827                                   2893.0                 10.0   \n",
       "828                                   1323.0                  0.0   \n",
       "829                                    973.0                  3.0   \n",
       "830                                     16.0                  0.0   \n",
       "831                                   1854.0                  0.0   \n",
       "\n",
       "     22:5 n-3 (DPA) (mg)  22:6 n-3 (DHA) (mg)  Caffeine (mg)  \\\n",
       "0                    0.0                  0.0            0.0   \n",
       "1                    0.0                  0.0            0.0   \n",
       "2                    0.0                  0.0            0.0   \n",
       "3                    0.0                  0.0            0.0   \n",
       "4                    0.0                  0.0            0.0   \n",
       "..                   ...                  ...            ...   \n",
       "827                 12.0                  9.0            0.0   \n",
       "828                  0.0                  0.0            0.0   \n",
       "829                  0.0                  0.0            0.0   \n",
       "830                  0.0                  0.0            0.0   \n",
       "831                  0.0                  0.0            0.0   \n",
       "\n",
       "     Theobromine (mg)  Price per Weight (Â£/100Gram)  GHG(kgco2eq/100g)  \n",
       "0                 0.0                      0.085000             0.1214  \n",
       "1                 0.0                      0.130667             0.0437  \n",
       "2                 0.0                      3.142857             0.1585  \n",
       "3                 0.0                      0.069000             0.0317  \n",
       "4                 0.0                      0.600000             0.2871  \n",
       "..                ...                           ...                ...  \n",
       "827               0.0                      0.500000             0.6092  \n",
       "828               0.0                      0.555556             0.6092  \n",
       "829               0.0                      0.118750             0.1441  \n",
       "830               0.0                      0.640000             0.1585  \n",
       "831               0.0                      0.600000             0.7282  \n",
       "\n",
       "[832 rows x 44 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nutrition_test = pd.read_csv(\"Test_20.csv\")\n",
    "nutrition_train = pd.read_csv(\"Train_80.csv\")\n",
    "nutrition_test = nutrition_test.dropna()\n",
    "nutrition_train = nutrition_train.dropna()\n",
    "nutrition_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the nutrition data, labelling X as this is the input to the SKlearn algorithm\n",
    "X_train = nutrition_train.iloc[:,2:42]\n",
    "nutrition_titles = X_train.columns\n",
    "X_test = nutrition_test.iloc[:,2:42]\n",
    "#extracting the greenhouse gas emissions \n",
    "y_test = nutrition_test.iloc[:,43:44]\n",
    "y_train = nutrition_train.iloc[:,43:44]\n",
    "y_test = np.ravel(y_test)\n",
    "y_train = np.ravel(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building d matrices of the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a baseline model and assess the mean of the carbon intensity, predicting that each food product gets the mean carbon intensity of the train set \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MAE is 0.90\n",
      "Baseline Mean from train is 0.87\n"
     ]
    }
   ],
   "source": [
    "# \"Learn\" the mean from the training data\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_train = np.mean(y_train)\n",
    "# Get predictions on the test set\n",
    "baseline_predictions = np.ones(y_test.shape) * mean_train\n",
    "# Compute MAE\n",
    "mae_baseline = mean_absolute_error(y_test, baseline_predictions)\n",
    "print(\"Baseline MAE is {:.2f}\".format(mae_baseline))\n",
    "print(\"Baseline Mean from train is {:.2f}\".format(mean_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # Parameters that i am going to tune.\n",
    "    'max_depth':6,\n",
    "    'min_child_weight': 1,\n",
    "    'eta':.3,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    # Other parameters\n",
    "    'objective':'reg:squarederror',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numboost and early stopping rounds for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-mae:0.54824\n",
      "[1]\tTest-mae:0.44361\n",
      "[2]\tTest-mae:0.36455\n",
      "[3]\tTest-mae:0.30109\n",
      "[4]\tTest-mae:0.27073\n",
      "[5]\tTest-mae:0.25210\n",
      "[6]\tTest-mae:0.23507\n",
      "[7]\tTest-mae:0.22786\n",
      "[8]\tTest-mae:0.21781\n",
      "[9]\tTest-mae:0.21155\n",
      "[10]\tTest-mae:0.20697\n",
      "[11]\tTest-mae:0.20415\n",
      "[12]\tTest-mae:0.19965\n",
      "[13]\tTest-mae:0.19912\n",
      "[14]\tTest-mae:0.19719\n",
      "[15]\tTest-mae:0.19652\n",
      "[16]\tTest-mae:0.19711\n",
      "[17]\tTest-mae:0.19753\n",
      "[18]\tTest-mae:0.19747\n",
      "[19]\tTest-mae:0.19795\n",
      "[20]\tTest-mae:0.19876\n",
      "[21]\tTest-mae:0.19974\n",
      "[22]\tTest-mae:0.19950\n",
      "[23]\tTest-mae:0.19928\n",
      "[24]\tTest-mae:0.19972\n",
      "[25]\tTest-mae:0.19856\n",
      "[26]\tTest-mae:0.19875\n",
      "[27]\tTest-mae:0.19851\n",
      "[28]\tTest-mae:0.19798\n",
      "[29]\tTest-mae:0.19761\n",
      "[30]\tTest-mae:0.19752\n",
      "[31]\tTest-mae:0.19751\n",
      "[32]\tTest-mae:0.19747\n",
      "[33]\tTest-mae:0.19746\n",
      "[34]\tTest-mae:0.19739\n",
      "[35]\tTest-mae:0.19770\n",
      "Best MAE: 0.20 with 16 rounds\n"
     ]
    }
   ],
   "source": [
    "# num boost round corresponds to the number of boosting rounds or trees to build \n",
    "#depends on other params so needed to be retuned \n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "#adding evaluation metric to the params dictionary\n",
    "#aiming to improve MAE \n",
    "params['eval_metric'] = \"mae\"\n",
    "#have to pass a max number of boosting rounds, set it really large but will probably find optimal number of trees before reaching \n",
    "#\n",
    "num_boost_round = 999\n",
    "\n",
    "#evals we are testing on our test data set \n",
    "# early stopping rounds is the number of rounds without improvement at which we shoudl stop \n",
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=20\n",
    ")\n",
    "\n",
    "print(\"Best MAE: {:.2f} with {} rounds\".format(\n",
    "                 model.best_score,\n",
    "                 model.best_iteration+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning other hyperparameters on the train set (CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-mae-mean</th>\n",
       "      <th>train-mae-std</th>\n",
       "      <th>test-mae-mean</th>\n",
       "      <th>test-mae-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.644792</td>\n",
       "      <td>0.013722</td>\n",
       "      <td>0.691110</td>\n",
       "      <td>0.050351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.482951</td>\n",
       "      <td>0.011244</td>\n",
       "      <td>0.563507</td>\n",
       "      <td>0.048779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.364859</td>\n",
       "      <td>0.009458</td>\n",
       "      <td>0.474381</td>\n",
       "      <td>0.047803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.279253</td>\n",
       "      <td>0.008103</td>\n",
       "      <td>0.413475</td>\n",
       "      <td>0.044625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.218189</td>\n",
       "      <td>0.008952</td>\n",
       "      <td>0.369198</td>\n",
       "      <td>0.040033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.263720</td>\n",
       "      <td>0.036337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.263720</td>\n",
       "      <td>0.036336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.000620</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.263722</td>\n",
       "      <td>0.036335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.000613</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.263720</td>\n",
       "      <td>0.036337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.000608</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.263719</td>\n",
       "      <td>0.036339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows Ã 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     train-mae-mean  train-mae-std  test-mae-mean  test-mae-std\n",
       "0          0.644792       0.013722       0.691110      0.050351\n",
       "1          0.482951       0.011244       0.563507      0.048779\n",
       "2          0.364859       0.009458       0.474381      0.047803\n",
       "3          0.279253       0.008103       0.413475      0.044625\n",
       "4          0.218189       0.008952       0.369198      0.040033\n",
       "..              ...            ...            ...           ...\n",
       "109        0.000649       0.000067       0.263720      0.036337\n",
       "110        0.000633       0.000050       0.263720      0.036336\n",
       "111        0.000620       0.000033       0.263722      0.036335\n",
       "112        0.000613       0.000020       0.263720      0.036337\n",
       "113        0.000608       0.000012       0.263719      0.036339\n",
       "\n",
       "[114 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dont have to pass it the test dataset as it is splitting the train into nfolds \n",
    "#keeping one of the folds for teest purposes \n",
    "cv_results = xgb.cv(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    seed=42,\n",
    "    nfold=5,\n",
    "    metrics={'mae'},\n",
    "    early_stopping_rounds=20\n",
    ")\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2637192"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results['test-mae-mean'].min()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## max_depth and min_child_weight \n",
    "### Max depth is the max number of nodes allowed from the root to the farthest leaf of a tree. Deeper trees model more complex relationships (adding more nodes) but deeper and deeper trees make splits less relevent, causing over fitting. Min child weight is the minimum weight (or number of samples if all samples have a weight of 1) required in order to create a new node in the tree. A smaller min child weight allows the algorithm to create children that correspond to fewer samples, more complex trees but again more likely to overfit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with max_depth=9, min_child_weight=5\n",
      "\tMAE 0.2624126 for 22 rounds\n",
      "CV with max_depth=9, min_child_weight=6\n",
      "\tMAE 0.26816579999999995 for 17 rounds\n",
      "CV with max_depth=9, min_child_weight=7\n",
      "\tMAE 0.264638 for 16 rounds\n",
      "CV with max_depth=10, min_child_weight=5\n",
      "\tMAE 0.260335 for 38 rounds\n",
      "CV with max_depth=10, min_child_weight=6\n",
      "\tMAE 0.2668154 for 54 rounds\n",
      "CV with max_depth=10, min_child_weight=7\n",
      "\tMAE 0.2742302 for 37 rounds\n",
      "CV with max_depth=11, min_child_weight=5\n",
      "\tMAE 0.2561362 for 43 rounds\n",
      "CV with max_depth=11, min_child_weight=6\n",
      "\tMAE 0.258045 for 79 rounds\n",
      "CV with max_depth=11, min_child_weight=7\n",
      "\tMAE 0.2709524 for 17 rounds\n",
      "Best params: 11, 5, MAE: 0.2561362\n"
     ]
    }
   ],
   "source": [
    "# list containing the combinations to try of the parmeters \n",
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(9,12)\n",
    "    for min_child_weight in range(5,8)\n",
    "]\n",
    "# running a cv of each of those pairs \n",
    "# Define initial best params and MAE\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))\n",
    "    # Update our parameters\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'mae'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    # Update best MAE\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (max_depth,min_child_weight)\n",
    "print(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['max_depth'] = 11\n",
    "params['min_child_weight'] = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsample and colsample_bytree tuning \n",
    "### these control the sampling of the dataset, which occurs at each boosting round. instead of using the whole train set I build a tree on slightly different data at each step, making the model less likely to overfit to a single sample or feature. subsample is the fraction of observations (rows) to subsample at each step. default is 1 meaning it uses all rows. Colsamplebytree is the fraction of features to use, again initially set to 1 meaning use all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [i/10. for i in range(7,11)]\n",
    "    for colsample in [i/10. for i in range(7,11)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with subsample=1.0, colsample=1.0\n",
      "\tMAE 0.2561362 for 43 rounds\n",
      "CV with subsample=1.0, colsample=0.9\n",
      "\tMAE 0.2623244 for 46 rounds\n",
      "CV with subsample=1.0, colsample=0.8\n",
      "\tMAE 0.25901240000000003 for 41 rounds\n",
      "CV with subsample=1.0, colsample=0.7\n",
      "\tMAE 0.28502700000000003 for 37 rounds\n",
      "CV with subsample=0.9, colsample=1.0\n",
      "\tMAE 0.283728 for 107 rounds\n",
      "CV with subsample=0.9, colsample=0.9\n",
      "\tMAE 0.290416 for 59 rounds\n",
      "CV with subsample=0.9, colsample=0.8\n",
      "\tMAE 0.2868442 for 79 rounds\n",
      "CV with subsample=0.9, colsample=0.7\n",
      "\tMAE 0.308263 for 34 rounds\n",
      "CV with subsample=0.8, colsample=1.0\n",
      "\tMAE 0.3005972 for 12 rounds\n",
      "CV with subsample=0.8, colsample=0.9\n",
      "\tMAE 0.2953984 for 16 rounds\n",
      "CV with subsample=0.8, colsample=0.8\n",
      "\tMAE 0.305223 for 10 rounds\n",
      "CV with subsample=0.8, colsample=0.7\n",
      "\tMAE 0.2844824 for 34 rounds\n",
      "CV with subsample=0.7, colsample=1.0\n",
      "\tMAE 0.30370299999999995 for 17 rounds\n",
      "CV with subsample=0.7, colsample=0.9\n",
      "\tMAE 0.3021992 for 9 rounds\n",
      "CV with subsample=0.7, colsample=0.8\n",
      "\tMAE 0.30486480000000005 for 10 rounds\n",
      "CV with subsample=0.7, colsample=0.7\n",
      "\tMAE 0.2966238 for 38 rounds\n",
      "Best params: 1.0, 1.0, MAE: 0.2561362\n"
     ]
    }
   ],
   "source": [
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "# We start by the largest values and go down to the smallest\n",
    "for subsample, colsample in reversed(gridsearch_params):\n",
    "    print(\"CV with subsample={}, colsample={}\".format(\n",
    "                             subsample,\n",
    "                             colsample))\n",
    "    # We update our parameters\n",
    "    params['subsample'] = subsample\n",
    "    params['colsample_bytree'] = colsample\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'mae'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    # Update best score\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (subsample,colsample)\n",
    "print(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so using all features and rows for this model improves results \n",
    "params['subsample'] = 1.\n",
    "params['colsample_bytree'] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETA paramter tuning \n",
    "### This is the learning rate, corresponds to the shrinkage of weights associated to features after each round, defines amount of correction at each step. ( as boosting corrects the errors of the previous round at each round). Usually having a lower eta makes the model more robust to overfitting (so usually the lower the better for the eta) but with the lower eta you need more boosting rounds, taking more time to train eg. see example below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "CV with eta=0.3\n",
      "Wall time: 952 ms\n",
      "\tMAE 0.2561362 for 43 rounds\n",
      "\n",
      "CV with eta=0.2\n",
      "Wall time: 645 ms\n",
      "\tMAE 0.26285800000000004 for 27 rounds\n",
      "\n",
      "CV with eta=0.1\n",
      "Wall time: 1.06 s\n",
      "\tMAE 0.2572242 for 53 rounds\n",
      "\n",
      "CV with eta=0.05\n",
      "Wall time: 2.06 s\n",
      "\tMAE 0.2570226 for 107 rounds\n",
      "\n",
      "CV with eta=0.01\n",
      "Wall time: 10.7 s\n",
      "\tMAE 0.2555792 for 639 rounds\n",
      "\n",
      "CV with eta=0.005\n",
      "Wall time: 16.5 s\n",
      "\tMAE 0.2586348 for 997 rounds\n",
      "\n",
      "Best params: 0.01, MAE: 0.2555792\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# This can take some timeâ¦\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "for eta in [.3, .2, .1, .05, .01, .005]:\n",
    "    print(\"CV with eta={}\".format(eta))\n",
    "    # We update our parameters\n",
    "    params['eta'] = eta\n",
    "    # Run and time CV\n",
    "    %time cv_results = xgb.cv(params,dtrain,num_boost_round=num_boost_round,seed=42,nfold=5,metrics=['mae'],early_stopping_rounds=10)\n",
    "    # Update best score\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\\n\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = eta\n",
    "print(\"Best params: {}, MAE: {}\".format(best_params, min_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lower and lower eta improves the MAE until 0.01, but does increase the time and number of rounds significantly, it is likely the MAE gets higher again in the eta = 0.005 due to underfitting caused by the small dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['eta'] = .01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 11,\n",
       " 'min_child_weight': 5,\n",
       " 'eta': 0.01,\n",
       " 'subsample': 1.0,\n",
       " 'colsample_bytree': 1.0,\n",
       " 'objective': 'reg:squarederror',\n",
       " 'eval_metric': 'mae'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-mae:0.70656\n",
      "[1]\tTest-mae:0.69981\n",
      "[2]\tTest-mae:0.69332\n",
      "[3]\tTest-mae:0.68704\n",
      "[4]\tTest-mae:0.68084\n",
      "[5]\tTest-mae:0.67468\n",
      "[6]\tTest-mae:0.66900\n",
      "[7]\tTest-mae:0.66310\n",
      "[8]\tTest-mae:0.65754\n",
      "[9]\tTest-mae:0.65194\n",
      "[10]\tTest-mae:0.64647\n",
      "[11]\tTest-mae:0.64095\n",
      "[12]\tTest-mae:0.63559\n",
      "[13]\tTest-mae:0.63097\n",
      "[14]\tTest-mae:0.62650\n",
      "[15]\tTest-mae:0.62230\n",
      "[16]\tTest-mae:0.61822\n",
      "[17]\tTest-mae:0.61418\n",
      "[18]\tTest-mae:0.60996\n",
      "[19]\tTest-mae:0.60589\n",
      "[20]\tTest-mae:0.60181\n",
      "[21]\tTest-mae:0.59786\n",
      "[22]\tTest-mae:0.59389\n",
      "[23]\tTest-mae:0.58980\n",
      "[24]\tTest-mae:0.58570\n",
      "[25]\tTest-mae:0.58204\n",
      "[26]\tTest-mae:0.57792\n",
      "[27]\tTest-mae:0.57444\n",
      "[28]\tTest-mae:0.57046\n",
      "[29]\tTest-mae:0.56676\n",
      "[30]\tTest-mae:0.56284\n",
      "[31]\tTest-mae:0.55908\n",
      "[32]\tTest-mae:0.55515\n",
      "[33]\tTest-mae:0.55108\n",
      "[34]\tTest-mae:0.54753\n",
      "[35]\tTest-mae:0.54335\n",
      "[36]\tTest-mae:0.53960\n",
      "[37]\tTest-mae:0.53592\n",
      "[38]\tTest-mae:0.53177\n",
      "[39]\tTest-mae:0.52794\n",
      "[40]\tTest-mae:0.52411\n",
      "[41]\tTest-mae:0.52028\n",
      "[42]\tTest-mae:0.51674\n",
      "[43]\tTest-mae:0.51302\n",
      "[44]\tTest-mae:0.50919\n",
      "[45]\tTest-mae:0.50571\n",
      "[46]\tTest-mae:0.50209\n",
      "[47]\tTest-mae:0.49857\n",
      "[48]\tTest-mae:0.49465\n",
      "[49]\tTest-mae:0.49144\n",
      "[50]\tTest-mae:0.48784\n",
      "[51]\tTest-mae:0.48437\n",
      "[52]\tTest-mae:0.48086\n",
      "[53]\tTest-mae:0.47747\n",
      "[54]\tTest-mae:0.47416\n",
      "[55]\tTest-mae:0.47060\n",
      "[56]\tTest-mae:0.46738\n",
      "[57]\tTest-mae:0.46407\n",
      "[58]\tTest-mae:0.46114\n",
      "[59]\tTest-mae:0.45791\n",
      "[60]\tTest-mae:0.45467\n",
      "[61]\tTest-mae:0.45143\n",
      "[62]\tTest-mae:0.44851\n",
      "[63]\tTest-mae:0.44533\n",
      "[64]\tTest-mae:0.44227\n",
      "[65]\tTest-mae:0.43905\n",
      "[66]\tTest-mae:0.43646\n",
      "[67]\tTest-mae:0.43311\n",
      "[68]\tTest-mae:0.43029\n",
      "[69]\tTest-mae:0.42717\n",
      "[70]\tTest-mae:0.42445\n",
      "[71]\tTest-mae:0.42188\n",
      "[72]\tTest-mae:0.41906\n",
      "[73]\tTest-mae:0.41631\n",
      "[74]\tTest-mae:0.41356\n",
      "[75]\tTest-mae:0.41103\n",
      "[76]\tTest-mae:0.40851\n",
      "[77]\tTest-mae:0.40577\n",
      "[78]\tTest-mae:0.40305\n",
      "[79]\tTest-mae:0.40029\n",
      "[80]\tTest-mae:0.39768\n",
      "[81]\tTest-mae:0.39522\n",
      "[82]\tTest-mae:0.39243\n",
      "[83]\tTest-mae:0.39005\n",
      "[84]\tTest-mae:0.38770\n",
      "[85]\tTest-mae:0.38490\n",
      "[86]\tTest-mae:0.38246\n",
      "[87]\tTest-mae:0.38006\n",
      "[88]\tTest-mae:0.37745\n",
      "[89]\tTest-mae:0.37512\n",
      "[90]\tTest-mae:0.37278\n",
      "[91]\tTest-mae:0.37048\n",
      "[92]\tTest-mae:0.36818\n",
      "[93]\tTest-mae:0.36598\n",
      "[94]\tTest-mae:0.36378\n",
      "[95]\tTest-mae:0.36164\n",
      "[96]\tTest-mae:0.35907\n",
      "[97]\tTest-mae:0.35710\n",
      "[98]\tTest-mae:0.35485\n",
      "[99]\tTest-mae:0.35241\n",
      "[100]\tTest-mae:0.35007\n",
      "[101]\tTest-mae:0.34793\n",
      "[102]\tTest-mae:0.34556\n",
      "[103]\tTest-mae:0.34345\n",
      "[104]\tTest-mae:0.34160\n",
      "[105]\tTest-mae:0.33959\n",
      "[106]\tTest-mae:0.33729\n",
      "[107]\tTest-mae:0.33516\n",
      "[108]\tTest-mae:0.33328\n",
      "[109]\tTest-mae:0.33133\n",
      "[110]\tTest-mae:0.32964\n",
      "[111]\tTest-mae:0.32778\n",
      "[112]\tTest-mae:0.32611\n",
      "[113]\tTest-mae:0.32414\n",
      "[114]\tTest-mae:0.32244\n",
      "[115]\tTest-mae:0.32111\n",
      "[116]\tTest-mae:0.31934\n",
      "[117]\tTest-mae:0.31781\n",
      "[118]\tTest-mae:0.31602\n",
      "[119]\tTest-mae:0.31470\n",
      "[120]\tTest-mae:0.31323\n",
      "[121]\tTest-mae:0.31166\n",
      "[122]\tTest-mae:0.31006\n",
      "[123]\tTest-mae:0.30860\n",
      "[124]\tTest-mae:0.30711\n",
      "[125]\tTest-mae:0.30579\n",
      "[126]\tTest-mae:0.30413\n",
      "[127]\tTest-mae:0.30252\n",
      "[128]\tTest-mae:0.30107\n",
      "[129]\tTest-mae:0.29982\n",
      "[130]\tTest-mae:0.29807\n",
      "[131]\tTest-mae:0.29638\n",
      "[132]\tTest-mae:0.29507\n",
      "[133]\tTest-mae:0.29347\n",
      "[134]\tTest-mae:0.29180\n",
      "[135]\tTest-mae:0.29026\n",
      "[136]\tTest-mae:0.28889\n",
      "[137]\tTest-mae:0.28753\n",
      "[138]\tTest-mae:0.28627\n",
      "[139]\tTest-mae:0.28520\n",
      "[140]\tTest-mae:0.28391\n",
      "[141]\tTest-mae:0.28273\n",
      "[142]\tTest-mae:0.28159\n",
      "[143]\tTest-mae:0.28064\n",
      "[144]\tTest-mae:0.27950\n",
      "[145]\tTest-mae:0.27866\n",
      "[146]\tTest-mae:0.27725\n",
      "[147]\tTest-mae:0.27637\n",
      "[148]\tTest-mae:0.27534\n",
      "[149]\tTest-mae:0.27442\n",
      "[150]\tTest-mae:0.27319\n",
      "[151]\tTest-mae:0.27242\n",
      "[152]\tTest-mae:0.27120\n",
      "[153]\tTest-mae:0.27039\n",
      "[154]\tTest-mae:0.26950\n",
      "[155]\tTest-mae:0.26829\n",
      "[156]\tTest-mae:0.26746\n",
      "[157]\tTest-mae:0.26668\n",
      "[158]\tTest-mae:0.26601\n",
      "[159]\tTest-mae:0.26497\n",
      "[160]\tTest-mae:0.26437\n",
      "[161]\tTest-mae:0.26359\n",
      "[162]\tTest-mae:0.26283\n",
      "[163]\tTest-mae:0.26215\n",
      "[164]\tTest-mae:0.26103\n",
      "[165]\tTest-mae:0.26046\n",
      "[166]\tTest-mae:0.25977\n",
      "[167]\tTest-mae:0.25899\n",
      "[168]\tTest-mae:0.25843\n",
      "[169]\tTest-mae:0.25775\n",
      "[170]\tTest-mae:0.25683\n",
      "[171]\tTest-mae:0.25631\n",
      "[172]\tTest-mae:0.25584\n",
      "[173]\tTest-mae:0.25515\n",
      "[174]\tTest-mae:0.25456\n",
      "[175]\tTest-mae:0.25369\n",
      "[176]\tTest-mae:0.25310\n",
      "[177]\tTest-mae:0.25254\n",
      "[178]\tTest-mae:0.25212\n",
      "[179]\tTest-mae:0.25159\n",
      "[180]\tTest-mae:0.25103\n",
      "[181]\tTest-mae:0.25013\n",
      "[182]\tTest-mae:0.24968\n",
      "[183]\tTest-mae:0.24876\n",
      "[184]\tTest-mae:0.24810\n",
      "[185]\tTest-mae:0.24767\n",
      "[186]\tTest-mae:0.24725\n",
      "[187]\tTest-mae:0.24679\n",
      "[188]\tTest-mae:0.24591\n",
      "[189]\tTest-mae:0.24547\n",
      "[190]\tTest-mae:0.24475\n",
      "[191]\tTest-mae:0.24430\n",
      "[192]\tTest-mae:0.24393\n",
      "[193]\tTest-mae:0.24345\n",
      "[194]\tTest-mae:0.24312\n",
      "[195]\tTest-mae:0.24268\n",
      "[196]\tTest-mae:0.24218\n",
      "[197]\tTest-mae:0.24141\n",
      "[198]\tTest-mae:0.24101\n",
      "[199]\tTest-mae:0.24066\n",
      "[200]\tTest-mae:0.24031\n",
      "[201]\tTest-mae:0.23989\n",
      "[202]\tTest-mae:0.23929\n",
      "[203]\tTest-mae:0.23864\n",
      "[204]\tTest-mae:0.23830\n",
      "[205]\tTest-mae:0.23770\n",
      "[206]\tTest-mae:0.23726\n",
      "[207]\tTest-mae:0.23681\n",
      "[208]\tTest-mae:0.23628\n",
      "[209]\tTest-mae:0.23603\n",
      "[210]\tTest-mae:0.23548\n",
      "[211]\tTest-mae:0.23497\n",
      "[212]\tTest-mae:0.23446\n",
      "[213]\tTest-mae:0.23393\n",
      "[214]\tTest-mae:0.23344\n",
      "[215]\tTest-mae:0.23300\n",
      "[216]\tTest-mae:0.23273\n",
      "[217]\tTest-mae:0.23228\n",
      "[218]\tTest-mae:0.23186\n",
      "[219]\tTest-mae:0.23160\n",
      "[220]\tTest-mae:0.23112\n",
      "[221]\tTest-mae:0.23073\n",
      "[222]\tTest-mae:0.23044\n",
      "[223]\tTest-mae:0.23001\n",
      "[224]\tTest-mae:0.22982\n",
      "[225]\tTest-mae:0.22927\n",
      "[226]\tTest-mae:0.22892\n",
      "[227]\tTest-mae:0.22865\n",
      "[228]\tTest-mae:0.22834\n",
      "[229]\tTest-mae:0.22783\n",
      "[230]\tTest-mae:0.22739\n",
      "[231]\tTest-mae:0.22689\n",
      "[232]\tTest-mae:0.22653\n",
      "[233]\tTest-mae:0.22618\n",
      "[234]\tTest-mae:0.22588\n",
      "[235]\tTest-mae:0.22567\n",
      "[236]\tTest-mae:0.22539\n",
      "[237]\tTest-mae:0.22505\n",
      "[238]\tTest-mae:0.22486\n",
      "[239]\tTest-mae:0.22446\n",
      "[240]\tTest-mae:0.22414\n",
      "[241]\tTest-mae:0.22369\n",
      "[242]\tTest-mae:0.22341\n",
      "[243]\tTest-mae:0.22318\n",
      "[244]\tTest-mae:0.22287\n",
      "[245]\tTest-mae:0.22265\n",
      "[246]\tTest-mae:0.22233\n",
      "[247]\tTest-mae:0.22203\n",
      "[248]\tTest-mae:0.22174\n",
      "[249]\tTest-mae:0.22144\n",
      "[250]\tTest-mae:0.22115\n",
      "[251]\tTest-mae:0.22085\n",
      "[252]\tTest-mae:0.22058\n",
      "[253]\tTest-mae:0.22032\n",
      "[254]\tTest-mae:0.22001\n",
      "[255]\tTest-mae:0.21973\n",
      "[256]\tTest-mae:0.21943\n",
      "[257]\tTest-mae:0.21920\n",
      "[258]\tTest-mae:0.21885\n",
      "[259]\tTest-mae:0.21868\n",
      "[260]\tTest-mae:0.21832\n",
      "[261]\tTest-mae:0.21804\n",
      "[262]\tTest-mae:0.21782\n",
      "[263]\tTest-mae:0.21755\n",
      "[264]\tTest-mae:0.21725\n",
      "[265]\tTest-mae:0.21698\n",
      "[266]\tTest-mae:0.21674\n",
      "[267]\tTest-mae:0.21650\n",
      "[268]\tTest-mae:0.21631\n",
      "[269]\tTest-mae:0.21616\n",
      "[270]\tTest-mae:0.21597\n",
      "[271]\tTest-mae:0.21585\n",
      "[272]\tTest-mae:0.21558\n",
      "[273]\tTest-mae:0.21533\n",
      "[274]\tTest-mae:0.21513\n",
      "[275]\tTest-mae:0.21487\n",
      "[276]\tTest-mae:0.21468\n",
      "[277]\tTest-mae:0.21447\n",
      "[278]\tTest-mae:0.21422\n",
      "[279]\tTest-mae:0.21397\n",
      "[280]\tTest-mae:0.21362\n",
      "[281]\tTest-mae:0.21338\n",
      "[282]\tTest-mae:0.21312\n",
      "[283]\tTest-mae:0.21281\n",
      "[284]\tTest-mae:0.21256\n",
      "[285]\tTest-mae:0.21230\n",
      "[286]\tTest-mae:0.21206\n",
      "[287]\tTest-mae:0.21182\n",
      "[288]\tTest-mae:0.21142\n",
      "[289]\tTest-mae:0.21103\n",
      "[290]\tTest-mae:0.21085\n",
      "[291]\tTest-mae:0.21045\n",
      "[292]\tTest-mae:0.21009\n",
      "[293]\tTest-mae:0.20972\n",
      "[294]\tTest-mae:0.20942\n",
      "[295]\tTest-mae:0.20906\n",
      "[296]\tTest-mae:0.20877\n",
      "[297]\tTest-mae:0.20845\n",
      "[298]\tTest-mae:0.20816\n",
      "[299]\tTest-mae:0.20785\n",
      "[300]\tTest-mae:0.20758\n",
      "[301]\tTest-mae:0.20730\n",
      "[302]\tTest-mae:0.20700\n",
      "[303]\tTest-mae:0.20675\n",
      "[304]\tTest-mae:0.20650\n",
      "[305]\tTest-mae:0.20616\n",
      "[306]\tTest-mae:0.20587\n",
      "[307]\tTest-mae:0.20556\n",
      "[308]\tTest-mae:0.20532\n",
      "[309]\tTest-mae:0.20506\n",
      "[310]\tTest-mae:0.20485\n",
      "[311]\tTest-mae:0.20467\n",
      "[312]\tTest-mae:0.20452\n",
      "[313]\tTest-mae:0.20435\n",
      "[314]\tTest-mae:0.20427\n",
      "[315]\tTest-mae:0.20411\n",
      "[316]\tTest-mae:0.20397\n",
      "[317]\tTest-mae:0.20389\n",
      "[318]\tTest-mae:0.20376\n",
      "[319]\tTest-mae:0.20359\n",
      "[320]\tTest-mae:0.20345\n",
      "[321]\tTest-mae:0.20336\n",
      "[322]\tTest-mae:0.20315\n",
      "[323]\tTest-mae:0.20295\n",
      "[324]\tTest-mae:0.20289\n",
      "[325]\tTest-mae:0.20264\n",
      "[326]\tTest-mae:0.20244\n",
      "[327]\tTest-mae:0.20239\n",
      "[328]\tTest-mae:0.20223\n",
      "[329]\tTest-mae:0.20225\n",
      "[330]\tTest-mae:0.20214\n",
      "[331]\tTest-mae:0.20203\n",
      "[332]\tTest-mae:0.20206\n",
      "[333]\tTest-mae:0.20196\n",
      "[334]\tTest-mae:0.20183\n",
      "[335]\tTest-mae:0.20172\n",
      "[336]\tTest-mae:0.20158\n",
      "[337]\tTest-mae:0.20142\n",
      "[338]\tTest-mae:0.20128\n",
      "[339]\tTest-mae:0.20115\n",
      "[340]\tTest-mae:0.20097\n",
      "[341]\tTest-mae:0.20083\n",
      "[342]\tTest-mae:0.20068\n",
      "[343]\tTest-mae:0.20057\n",
      "[344]\tTest-mae:0.20037\n",
      "[345]\tTest-mae:0.20027\n",
      "[346]\tTest-mae:0.20016\n",
      "[347]\tTest-mae:0.19999\n",
      "[348]\tTest-mae:0.19988\n",
      "[349]\tTest-mae:0.19972\n",
      "[350]\tTest-mae:0.19961\n",
      "[351]\tTest-mae:0.19946\n",
      "[352]\tTest-mae:0.19933\n",
      "[353]\tTest-mae:0.19917\n",
      "[354]\tTest-mae:0.19908\n",
      "[355]\tTest-mae:0.19894\n",
      "[356]\tTest-mae:0.19881\n",
      "[357]\tTest-mae:0.19871\n",
      "[358]\tTest-mae:0.19866\n",
      "[359]\tTest-mae:0.19851\n",
      "[360]\tTest-mae:0.19843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[361]\tTest-mae:0.19835\n",
      "[362]\tTest-mae:0.19823\n",
      "[363]\tTest-mae:0.19814\n",
      "[364]\tTest-mae:0.19806\n",
      "[365]\tTest-mae:0.19799\n",
      "[366]\tTest-mae:0.19796\n",
      "[367]\tTest-mae:0.19792\n",
      "[368]\tTest-mae:0.19781\n",
      "[369]\tTest-mae:0.19774\n",
      "[370]\tTest-mae:0.19768\n",
      "[371]\tTest-mae:0.19770\n",
      "[372]\tTest-mae:0.19765\n",
      "[373]\tTest-mae:0.19760\n",
      "[374]\tTest-mae:0.19755\n",
      "[375]\tTest-mae:0.19750\n",
      "[376]\tTest-mae:0.19740\n",
      "[377]\tTest-mae:0.19737\n",
      "[378]\tTest-mae:0.19734\n",
      "[379]\tTest-mae:0.19733\n",
      "[380]\tTest-mae:0.19728\n",
      "[381]\tTest-mae:0.19726\n",
      "[382]\tTest-mae:0.19723\n",
      "[383]\tTest-mae:0.19718\n",
      "[384]\tTest-mae:0.19718\n",
      "[385]\tTest-mae:0.19715\n",
      "[386]\tTest-mae:0.19716\n",
      "[387]\tTest-mae:0.19709\n",
      "[388]\tTest-mae:0.19706\n",
      "[389]\tTest-mae:0.19702\n",
      "[390]\tTest-mae:0.19697\n",
      "[391]\tTest-mae:0.19693\n",
      "[392]\tTest-mae:0.19685\n",
      "[393]\tTest-mae:0.19681\n",
      "[394]\tTest-mae:0.19676\n",
      "[395]\tTest-mae:0.19674\n",
      "[396]\tTest-mae:0.19673\n",
      "[397]\tTest-mae:0.19666\n",
      "[398]\tTest-mae:0.19658\n",
      "[399]\tTest-mae:0.19654\n",
      "[400]\tTest-mae:0.19651\n",
      "[401]\tTest-mae:0.19646\n",
      "[402]\tTest-mae:0.19640\n",
      "[403]\tTest-mae:0.19638\n",
      "[404]\tTest-mae:0.19635\n",
      "[405]\tTest-mae:0.19630\n",
      "[406]\tTest-mae:0.19620\n",
      "[407]\tTest-mae:0.19609\n",
      "[408]\tTest-mae:0.19599\n",
      "[409]\tTest-mae:0.19589\n",
      "[410]\tTest-mae:0.19580\n",
      "[411]\tTest-mae:0.19573\n",
      "[412]\tTest-mae:0.19564\n",
      "[413]\tTest-mae:0.19554\n",
      "[414]\tTest-mae:0.19547\n",
      "[415]\tTest-mae:0.19540\n",
      "[416]\tTest-mae:0.19534\n",
      "[417]\tTest-mae:0.19529\n",
      "[418]\tTest-mae:0.19526\n",
      "[419]\tTest-mae:0.19526\n",
      "[420]\tTest-mae:0.19519\n",
      "[421]\tTest-mae:0.19517\n",
      "[422]\tTest-mae:0.19516\n",
      "[423]\tTest-mae:0.19509\n",
      "[424]\tTest-mae:0.19505\n",
      "[425]\tTest-mae:0.19502\n",
      "[426]\tTest-mae:0.19499\n",
      "[427]\tTest-mae:0.19495\n",
      "[428]\tTest-mae:0.19493\n",
      "[429]\tTest-mae:0.19493\n",
      "[430]\tTest-mae:0.19488\n",
      "[431]\tTest-mae:0.19482\n",
      "[432]\tTest-mae:0.19481\n",
      "[433]\tTest-mae:0.19475\n",
      "[434]\tTest-mae:0.19476\n",
      "[435]\tTest-mae:0.19470\n",
      "[436]\tTest-mae:0.19469\n",
      "[437]\tTest-mae:0.19460\n",
      "[438]\tTest-mae:0.19451\n",
      "[439]\tTest-mae:0.19441\n",
      "[440]\tTest-mae:0.19432\n",
      "[441]\tTest-mae:0.19427\n",
      "[442]\tTest-mae:0.19420\n",
      "[443]\tTest-mae:0.19413\n",
      "[444]\tTest-mae:0.19407\n",
      "[445]\tTest-mae:0.19399\n",
      "[446]\tTest-mae:0.19393\n",
      "[447]\tTest-mae:0.19386\n",
      "[448]\tTest-mae:0.19384\n",
      "[449]\tTest-mae:0.19378\n",
      "[450]\tTest-mae:0.19378\n",
      "[451]\tTest-mae:0.19372\n",
      "[452]\tTest-mae:0.19365\n",
      "[453]\tTest-mae:0.19358\n",
      "[454]\tTest-mae:0.19351\n",
      "[455]\tTest-mae:0.19344\n",
      "[456]\tTest-mae:0.19339\n",
      "[457]\tTest-mae:0.19335\n",
      "[458]\tTest-mae:0.19329\n",
      "[459]\tTest-mae:0.19329\n",
      "[460]\tTest-mae:0.19323\n",
      "[461]\tTest-mae:0.19322\n",
      "[462]\tTest-mae:0.19318\n",
      "[463]\tTest-mae:0.19313\n",
      "[464]\tTest-mae:0.19311\n",
      "[465]\tTest-mae:0.19314\n",
      "[466]\tTest-mae:0.19311\n",
      "[467]\tTest-mae:0.19307\n",
      "[468]\tTest-mae:0.19304\n",
      "[469]\tTest-mae:0.19306\n",
      "[470]\tTest-mae:0.19304\n",
      "[471]\tTest-mae:0.19303\n",
      "[472]\tTest-mae:0.19300\n",
      "[473]\tTest-mae:0.19296\n",
      "[474]\tTest-mae:0.19297\n",
      "[475]\tTest-mae:0.19297\n",
      "[476]\tTest-mae:0.19297\n",
      "[477]\tTest-mae:0.19298\n",
      "[478]\tTest-mae:0.19301\n",
      "[479]\tTest-mae:0.19301\n",
      "[480]\tTest-mae:0.19297\n",
      "[481]\tTest-mae:0.19299\n",
      "[482]\tTest-mae:0.19299\n",
      "[483]\tTest-mae:0.19295\n",
      "[484]\tTest-mae:0.19296\n",
      "[485]\tTest-mae:0.19299\n",
      "[486]\tTest-mae:0.19298\n",
      "[487]\tTest-mae:0.19295\n",
      "[488]\tTest-mae:0.19295\n",
      "[489]\tTest-mae:0.19295\n",
      "[490]\tTest-mae:0.19295\n",
      "[491]\tTest-mae:0.19294\n",
      "[492]\tTest-mae:0.19295\n",
      "[493]\tTest-mae:0.19296\n",
      "[494]\tTest-mae:0.19296\n",
      "[495]\tTest-mae:0.19295\n",
      "[496]\tTest-mae:0.19293\n",
      "[497]\tTest-mae:0.19293\n",
      "[498]\tTest-mae:0.19288\n",
      "[499]\tTest-mae:0.19289\n",
      "[500]\tTest-mae:0.19286\n",
      "[501]\tTest-mae:0.19290\n",
      "[502]\tTest-mae:0.19287\n",
      "[503]\tTest-mae:0.19291\n",
      "[504]\tTest-mae:0.19294\n",
      "[505]\tTest-mae:0.19292\n",
      "[506]\tTest-mae:0.19288\n",
      "[507]\tTest-mae:0.19286\n",
      "[508]\tTest-mae:0.19284\n",
      "[509]\tTest-mae:0.19283\n",
      "[510]\tTest-mae:0.19279\n",
      "[511]\tTest-mae:0.19282\n",
      "[512]\tTest-mae:0.19285\n",
      "[513]\tTest-mae:0.19285\n",
      "[514]\tTest-mae:0.19280\n",
      "[515]\tTest-mae:0.19282\n",
      "[516]\tTest-mae:0.19281\n",
      "[517]\tTest-mae:0.19283\n",
      "[518]\tTest-mae:0.19279\n",
      "[519]\tTest-mae:0.19276\n",
      "[520]\tTest-mae:0.19273\n",
      "[521]\tTest-mae:0.19276\n",
      "[522]\tTest-mae:0.19276\n",
      "[523]\tTest-mae:0.19277\n",
      "[524]\tTest-mae:0.19274\n",
      "[525]\tTest-mae:0.19276\n",
      "[526]\tTest-mae:0.19276\n",
      "[527]\tTest-mae:0.19276\n",
      "[528]\tTest-mae:0.19277\n",
      "[529]\tTest-mae:0.19276\n",
      "[530]\tTest-mae:0.19276\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
