{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "import tensorflow\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>Food Group</th>\n",
       "      <th>Price (£)</th>\n",
       "      <th>Weight (GRAMS)</th>\n",
       "      <th>Price per Weight (£/100Gram)</th>\n",
       "      <th>Carbon Group</th>\n",
       "      <th>Land use (m2/100g)</th>\n",
       "      <th>GHG(kgco2eq/100g)</th>\n",
       "      <th>Water use (L/100g)</th>\n",
       "      <th>Acidifying emissions(kgSO2eq per 100g)</th>\n",
       "      <th>...</th>\n",
       "      <th>Carotene, alpha (mcg)</th>\n",
       "      <th>Lycopene (mcg)</th>\n",
       "      <th>Lutein + Zeaxanthin (mcg)</th>\n",
       "      <th>Fatty acids, total monounsaturated (mg)</th>\n",
       "      <th>Fatty acids, total polyunsaturated (mg)</th>\n",
       "      <th>20:5 n-3 (EPA) (mg)</th>\n",
       "      <th>22:5 n-3 (DPA) (mg)</th>\n",
       "      <th>22:6 n-3 (DHA) (mg)</th>\n",
       "      <th>Caffeine (mg)</th>\n",
       "      <th>Theobromine (mg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Waffles Buttermilk Frozen Ready-To-Heat</td>\n",
       "      <td>Baked Foods</td>\n",
       "      <td>1.50</td>\n",
       "      <td>567.0</td>\n",
       "      <td>0.264550</td>\n",
       "      <td>Bread products</td>\n",
       "      <td>0.3482</td>\n",
       "      <td>0.1441</td>\n",
       "      <td>56.7</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>4530.0</td>\n",
       "      <td>1445.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Waffle Buttermilk Frozen Ready-To-Heat Toasted</td>\n",
       "      <td>Baked Foods</td>\n",
       "      <td>1.50</td>\n",
       "      <td>567.0</td>\n",
       "      <td>0.264550</td>\n",
       "      <td>Bread products</td>\n",
       "      <td>0.3482</td>\n",
       "      <td>0.1441</td>\n",
       "      <td>56.7</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>5292.0</td>\n",
       "      <td>1502.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Dutch Apple Pie</td>\n",
       "      <td>Baked Foods</td>\n",
       "      <td>2.80</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>Bread products</td>\n",
       "      <td>0.3482</td>\n",
       "      <td>0.1441</td>\n",
       "      <td>56.7</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5797.0</td>\n",
       "      <td>2117.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Bread White Wheat</td>\n",
       "      <td>Baked Foods</td>\n",
       "      <td>0.95</td>\n",
       "      <td>800.0</td>\n",
       "      <td>0.118750</td>\n",
       "      <td>Bread products</td>\n",
       "      <td>0.3482</td>\n",
       "      <td>0.1441</td>\n",
       "      <td>56.7</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>973.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Bagels Wheat</td>\n",
       "      <td>Baked Foods</td>\n",
       "      <td>1.60</td>\n",
       "      <td>450.0</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>Bread products</td>\n",
       "      <td>0.3482</td>\n",
       "      <td>0.1441</td>\n",
       "      <td>56.7</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>936.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1218</td>\n",
       "      <td>Plantain Fried</td>\n",
       "      <td>Vegetables</td>\n",
       "      <td>0.90</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.058824</td>\n",
       "      <td>Other vegetables</td>\n",
       "      <td>0.0310</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>...</td>\n",
       "      <td>418.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4099.0</td>\n",
       "      <td>4079.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1219</td>\n",
       "      <td>Romaine Lettuce Raw</td>\n",
       "      <td>Vegetables</td>\n",
       "      <td>1.00</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>Other vegetables</td>\n",
       "      <td>0.0310</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4204.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>Palak Paneer</td>\n",
       "      <td>Vegetables</td>\n",
       "      <td>3.75</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>Cheese</td>\n",
       "      <td>8.0642</td>\n",
       "      <td>2.1240</td>\n",
       "      <td>473.5</td>\n",
       "      <td>0.014894</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>4097.0</td>\n",
       "      <td>2402.0</td>\n",
       "      <td>2112.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1221</td>\n",
       "      <td>Carrots Raw Salad</td>\n",
       "      <td>Vegetables</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.041000</td>\n",
       "      <td>Other vegetables</td>\n",
       "      <td>0.0310</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>...</td>\n",
       "      <td>2157.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>3498.0</td>\n",
       "      <td>9319.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1222</td>\n",
       "      <td>Corn on the cob</td>\n",
       "      <td>Vegetables</td>\n",
       "      <td>1.50</td>\n",
       "      <td>875.0</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>Other vegetables</td>\n",
       "      <td>0.0310</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>693.0</td>\n",
       "      <td>373.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1042 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name   Food Group  Price (£)  \\\n",
       "1            Waffles Buttermilk Frozen Ready-To-Heat  Baked Foods       1.50   \n",
       "2     Waffle Buttermilk Frozen Ready-To-Heat Toasted  Baked Foods       1.50   \n",
       "5                                    Dutch Apple Pie  Baked Foods       2.80   \n",
       "9                                  Bread White Wheat  Baked Foods       0.95   \n",
       "10                                      Bagels Wheat  Baked Foods       1.60   \n",
       "...                                              ...          ...        ...   \n",
       "1218                                 Plantain Fried    Vegetables       0.90   \n",
       "1219                             Romaine Lettuce Raw   Vegetables       1.00   \n",
       "1220                                    Palak Paneer   Vegetables       3.75   \n",
       "1221                               Carrots Raw Salad   Vegetables       0.41   \n",
       "1222                                Corn on the cob    Vegetables       1.50   \n",
       "\n",
       "      Weight (GRAMS)  Price per Weight (£/100Gram)       Carbon Group  \\\n",
       "1              567.0                      0.264550    Bread products    \n",
       "2              567.0                      0.264550    Bread products    \n",
       "5              500.0                      0.560000    Bread products    \n",
       "9              800.0                      0.118750    Bread products    \n",
       "10             450.0                      0.355556    Bread products    \n",
       "...              ...                           ...                ...   \n",
       "1218            85.0                      1.058824  Other vegetables    \n",
       "1219           400.0                      0.250000  Other vegetables    \n",
       "1220           500.0                      0.750000            Cheese    \n",
       "1221          1000.0                      0.041000  Other vegetables    \n",
       "1222           875.0                      0.171429  Other vegetables    \n",
       "\n",
       "      Land use (m2/100g)  GHG(kgco2eq/100g)  Water use (L/100g)  \\\n",
       "1                 0.3482             0.1441                56.7   \n",
       "2                 0.3482             0.1441                56.7   \n",
       "5                 0.3482             0.1441                56.7   \n",
       "9                 0.3482             0.1441                56.7   \n",
       "10                0.3482             0.1441                56.7   \n",
       "...                  ...                ...                 ...   \n",
       "1218              0.0310             0.0455                 8.3   \n",
       "1219              0.0310             0.0455                 8.3   \n",
       "1220              8.0642             2.1240               473.5   \n",
       "1221              0.0310             0.0455                 8.3   \n",
       "1222              0.0310             0.0455                 8.3   \n",
       "\n",
       "      Acidifying emissions(kgSO2eq per 100g)  ...  Carotene, alpha (mcg)  \\\n",
       "1                                   0.001209  ...                    0.0   \n",
       "2                                   0.001209  ...                    0.0   \n",
       "5                                   0.001209  ...                    0.0   \n",
       "9                                   0.001209  ...                    0.0   \n",
       "10                                  0.001209  ...                    0.0   \n",
       "...                                      ...  ...                    ...   \n",
       "1218                                0.000531  ...                  418.0   \n",
       "1219                                0.000531  ...                    0.0   \n",
       "1220                                0.014894  ...                   12.0   \n",
       "1221                                0.000531  ...                 2157.0   \n",
       "1222                                0.000531  ...                    6.0   \n",
       "\n",
       "      Lycopene (mcg)  Lutein + Zeaxanthin (mcg)  \\\n",
       "1                0.0                       63.0   \n",
       "2                0.0                       66.0   \n",
       "5                1.0                       42.0   \n",
       "9                0.0                       25.0   \n",
       "10               0.0                       88.0   \n",
       "...              ...                        ...   \n",
       "1218             0.0                       29.0   \n",
       "1219             0.0                     4204.0   \n",
       "1220           313.0                     4097.0   \n",
       "1221             1.0                      162.0   \n",
       "1222             0.0                      693.0   \n",
       "\n",
       "      Fatty acids, total monounsaturated (mg)  \\\n",
       "1                                      4530.0   \n",
       "2                                      5292.0   \n",
       "5                                      5797.0   \n",
       "9                                       393.0   \n",
       "10                                      290.0   \n",
       "...                                       ...   \n",
       "1218                                   4099.0   \n",
       "1219                                      7.0   \n",
       "1220                                   2402.0   \n",
       "1221                                   3498.0   \n",
       "1222                                    373.0   \n",
       "\n",
       "      Fatty acids, total polyunsaturated (mg)  20:5 n-3 (EPA) (mg)  \\\n",
       "1                                      1445.0                 12.0   \n",
       "2                                      1502.0                 13.0   \n",
       "5                                      2117.0                  0.0   \n",
       "9                                       973.0                  3.0   \n",
       "10                                      936.0                  0.0   \n",
       "...                                       ...                  ...   \n",
       "1218                                   4079.0                  0.0   \n",
       "1219                                    126.0                  0.0   \n",
       "1220                                   2112.0                  0.0   \n",
       "1221                                   9319.0                  0.0   \n",
       "1222                                    518.0                  0.0   \n",
       "\n",
       "      22:5 n-3 (DPA) (mg)  22:6 n-3 (DHA) (mg)  Caffeine (mg)  \\\n",
       "1                     0.0                  7.0            0.0   \n",
       "2                     0.0                  8.0            0.0   \n",
       "5                     0.0                  0.0            0.0   \n",
       "9                     0.0                  0.0            0.0   \n",
       "10                    0.0                  0.0            0.0   \n",
       "...                   ...                  ...            ...   \n",
       "1218                  0.0                  0.0            0.0   \n",
       "1219                  0.0                  0.0            0.0   \n",
       "1220                  0.0                  0.0            0.0   \n",
       "1221                  0.0                  1.0            0.0   \n",
       "1222                  0.0                  0.0            0.0   \n",
       "\n",
       "      Theobromine (mg)  \n",
       "1                  0.0  \n",
       "2                  0.0  \n",
       "5                  0.0  \n",
       "9                  0.0  \n",
       "10                 0.0  \n",
       "...                ...  \n",
       "1218               0.0  \n",
       "1219               0.0  \n",
       "1220               0.0  \n",
       "1221               0.0  \n",
       "1222               0.0  \n",
       "\n",
       "[1042 rows x 51 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nutrition = pd.read_pickle(\"./Nutrition_Full_Features.pkl\")\n",
    "nutrition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data for features\n",
    "X = nutrition.iloc[:, 11:]\n",
    "y = nutrition.iloc[:, 4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Calories</th>\n",
       "      <th>Fat (g)</th>\n",
       "      <th>Protein (g)</th>\n",
       "      <th>Carbohydrate (g)</th>\n",
       "      <th>Sugars (g)</th>\n",
       "      <th>Fiber (g)</th>\n",
       "      <th>Saturated Fats (g)</th>\n",
       "      <th>Calcium (mg)</th>\n",
       "      <th>Iron, Fe (mg)</th>\n",
       "      <th>Potassium, K (mg)</th>\n",
       "      <th>...</th>\n",
       "      <th>Carotene, alpha (mcg)</th>\n",
       "      <th>Lycopene (mcg)</th>\n",
       "      <th>Lutein + Zeaxanthin (mcg)</th>\n",
       "      <th>Fatty acids, total monounsaturated (mg)</th>\n",
       "      <th>Fatty acids, total polyunsaturated (mg)</th>\n",
       "      <th>20:5 n-3 (EPA) (mg)</th>\n",
       "      <th>22:5 n-3 (DPA) (mg)</th>\n",
       "      <th>22:6 n-3 (DHA) (mg)</th>\n",
       "      <th>Caffeine (mg)</th>\n",
       "      <th>Theobromine (mg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>9.22</td>\n",
       "      <td>6.58</td>\n",
       "      <td>41.05</td>\n",
       "      <td>4.30</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.898</td>\n",
       "      <td>279</td>\n",
       "      <td>6.04</td>\n",
       "      <td>126.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>4530.0</td>\n",
       "      <td>1445.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>309</td>\n",
       "      <td>9.49</td>\n",
       "      <td>7.42</td>\n",
       "      <td>48.39</td>\n",
       "      <td>4.41</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.275</td>\n",
       "      <td>299</td>\n",
       "      <td>6.59</td>\n",
       "      <td>138.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>5292.0</td>\n",
       "      <td>1502.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>290</td>\n",
       "      <td>11.50</td>\n",
       "      <td>2.17</td>\n",
       "      <td>44.54</td>\n",
       "      <td>22.02</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.313</td>\n",
       "      <td>14</td>\n",
       "      <td>0.91</td>\n",
       "      <td>76.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5797.0</td>\n",
       "      <td>2117.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>238</td>\n",
       "      <td>2.15</td>\n",
       "      <td>10.66</td>\n",
       "      <td>43.91</td>\n",
       "      <td>5.00</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.630</td>\n",
       "      <td>684</td>\n",
       "      <td>4.89</td>\n",
       "      <td>127.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>973.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>250</td>\n",
       "      <td>1.53</td>\n",
       "      <td>10.20</td>\n",
       "      <td>48.89</td>\n",
       "      <td>6.12</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>20</td>\n",
       "      <td>2.76</td>\n",
       "      <td>165.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>936.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1218</td>\n",
       "      <td>241</td>\n",
       "      <td>10.16</td>\n",
       "      <td>1.66</td>\n",
       "      <td>40.60</td>\n",
       "      <td>19.10</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.507</td>\n",
       "      <td>4</td>\n",
       "      <td>0.78</td>\n",
       "      <td>572.0</td>\n",
       "      <td>...</td>\n",
       "      <td>418.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4099.0</td>\n",
       "      <td>4079.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1219</td>\n",
       "      <td>19</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.39</td>\n",
       "      <td>3.78</td>\n",
       "      <td>0.71</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.053</td>\n",
       "      <td>62</td>\n",
       "      <td>0.90</td>\n",
       "      <td>327.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4204.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>96</td>\n",
       "      <td>6.84</td>\n",
       "      <td>5.23</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.486</td>\n",
       "      <td>70</td>\n",
       "      <td>1.15</td>\n",
       "      <td>269.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>4097.0</td>\n",
       "      <td>2402.0</td>\n",
       "      <td>2112.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1221</td>\n",
       "      <td>208</td>\n",
       "      <td>15.70</td>\n",
       "      <td>1.22</td>\n",
       "      <td>17.17</td>\n",
       "      <td>11.23</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.452</td>\n",
       "      <td>30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>309.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2157.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>3498.0</td>\n",
       "      <td>9319.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1222</td>\n",
       "      <td>67</td>\n",
       "      <td>1.22</td>\n",
       "      <td>2.28</td>\n",
       "      <td>14.30</td>\n",
       "      <td>4.43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.244</td>\n",
       "      <td>3</td>\n",
       "      <td>0.27</td>\n",
       "      <td>132.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>693.0</td>\n",
       "      <td>373.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1042 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Calories  Fat (g)  Protein (g)  Carbohydrate (g)  Sugars (g)  Fiber (g)  \\\n",
       "1          273     9.22         6.58             41.05        4.30        2.2   \n",
       "2          309     9.49         7.42             48.39        4.41        2.6   \n",
       "5          290    11.50         2.17             44.54       22.02        1.6   \n",
       "9          238     2.15        10.66             43.91        5.00        9.2   \n",
       "10         250     1.53        10.20             48.89        6.12        4.1   \n",
       "...        ...      ...          ...               ...         ...        ...   \n",
       "1218       241    10.16         1.66             40.60       19.10        2.9   \n",
       "1219        19     0.27         1.39              3.78        0.71        3.1   \n",
       "1220        96     6.84         5.23              4.32        1.89        1.2   \n",
       "1221       208    15.70         1.22             17.17       11.23        2.3   \n",
       "1222        67     1.22         2.28             14.30        4.43        2.0   \n",
       "\n",
       "      Saturated Fats (g)  Calcium (mg)  Iron, Fe (mg)  Potassium, K (mg)  ...  \\\n",
       "1                  1.898           279           6.04              126.0  ...   \n",
       "2                  2.275           299           6.59              138.0  ...   \n",
       "5                  2.313            14           0.91               76.0  ...   \n",
       "9                  0.630           684           4.89              127.0  ...   \n",
       "10                 0.000            20           2.76              165.0  ...   \n",
       "...                  ...           ...            ...                ...  ...   \n",
       "1218               1.507             4           0.78              572.0  ...   \n",
       "1219               0.053            62           0.90              327.0  ...   \n",
       "1220               1.486            70           1.15              269.0  ...   \n",
       "1221               2.452            30           0.49              309.0  ...   \n",
       "1222               0.244             3           0.27              132.0  ...   \n",
       "\n",
       "      Carotene, alpha (mcg)  Lycopene (mcg)  Lutein + Zeaxanthin (mcg)  \\\n",
       "1                       0.0             0.0                       63.0   \n",
       "2                       0.0             0.0                       66.0   \n",
       "5                       0.0             1.0                       42.0   \n",
       "9                       0.0             0.0                       25.0   \n",
       "10                      0.0             0.0                       88.0   \n",
       "...                     ...             ...                        ...   \n",
       "1218                  418.0             0.0                       29.0   \n",
       "1219                    0.0             0.0                     4204.0   \n",
       "1220                   12.0           313.0                     4097.0   \n",
       "1221                 2157.0             1.0                      162.0   \n",
       "1222                    6.0             0.0                      693.0   \n",
       "\n",
       "      Fatty acids, total monounsaturated (mg)  \\\n",
       "1                                      4530.0   \n",
       "2                                      5292.0   \n",
       "5                                      5797.0   \n",
       "9                                       393.0   \n",
       "10                                      290.0   \n",
       "...                                       ...   \n",
       "1218                                   4099.0   \n",
       "1219                                      7.0   \n",
       "1220                                   2402.0   \n",
       "1221                                   3498.0   \n",
       "1222                                    373.0   \n",
       "\n",
       "      Fatty acids, total polyunsaturated (mg)  20:5 n-3 (EPA) (mg)  \\\n",
       "1                                      1445.0                 12.0   \n",
       "2                                      1502.0                 13.0   \n",
       "5                                      2117.0                  0.0   \n",
       "9                                       973.0                  3.0   \n",
       "10                                      936.0                  0.0   \n",
       "...                                       ...                  ...   \n",
       "1218                                   4079.0                  0.0   \n",
       "1219                                    126.0                  0.0   \n",
       "1220                                   2112.0                  0.0   \n",
       "1221                                   9319.0                  0.0   \n",
       "1222                                    518.0                  0.0   \n",
       "\n",
       "      22:5 n-3 (DPA) (mg)  22:6 n-3 (DHA) (mg)  Caffeine (mg)  \\\n",
       "1                     0.0                  7.0            0.0   \n",
       "2                     0.0                  8.0            0.0   \n",
       "5                     0.0                  0.0            0.0   \n",
       "9                     0.0                  0.0            0.0   \n",
       "10                    0.0                  0.0            0.0   \n",
       "...                   ...                  ...            ...   \n",
       "1218                  0.0                  0.0            0.0   \n",
       "1219                  0.0                  0.0            0.0   \n",
       "1220                  0.0                  0.0            0.0   \n",
       "1221                  0.0                  1.0            0.0   \n",
       "1222                  0.0                  0.0            0.0   \n",
       "\n",
       "      Theobromine (mg)  \n",
       "1                  0.0  \n",
       "2                  0.0  \n",
       "5                  0.0  \n",
       "9                  0.0  \n",
       "10                 0.0  \n",
       "...                ...  \n",
       "1218               0.0  \n",
       "1219               0.0  \n",
       "1220               0.0  \n",
       "1221               0.0  \n",
       "1222               0.0  \n",
       "\n",
       "[1042 rows x 40 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1       0.264550\n",
       "2       0.264550\n",
       "5       0.560000\n",
       "9       0.118750\n",
       "10      0.355556\n",
       "          ...   \n",
       "1218    1.058824\n",
       "1219    0.250000\n",
       "1220    0.750000\n",
       "1221    0.041000\n",
       "1222    0.171429\n",
       "Name: Price per Weight (£/100Gram), Length: 1042, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# command/\n",
    "#only normalising X not y. Is this right?\n",
    "# norm_X = preprocessing.normalize(X, axis=0) #collum instead of row\n",
    "# norm_X = pd.DataFrame(norm_X, columns = X.columns)\n",
    "# X=norm_X\n",
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.ravel(y)\n",
    "X = X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "84/84 [==============================] - 0s 743us/step - loss: 9.5617 - mse: 9.5617\n",
      "Epoch 2/100\n",
      "84/84 [==============================] - 0s 758us/step - loss: 103.8514 - mse: 103.8514\n",
      "Epoch 3/100\n",
      "84/84 [==============================] - 0s 747us/step - loss: 68.8082 - mse: 68.8082\n",
      "Epoch 4/100\n",
      "84/84 [==============================] - 0s 696us/step - loss: 25.8201 - mse: 25.8201\n",
      "Epoch 5/100\n",
      "84/84 [==============================] - 0s 731us/step - loss: 103.9792 - mse: 103.9791\n",
      "Epoch 6/100\n",
      "84/84 [==============================] - 0s 767us/step - loss: 211.9898 - mse: 211.9898\n",
      "Epoch 7/100\n",
      "84/84 [==============================] - 0s 738us/step - loss: 72.7158 - mse: 72.7158\n",
      "Epoch 8/100\n",
      "84/84 [==============================] - 0s 686us/step - loss: 24.5408 - mse: 24.5408\n",
      "Epoch 9/100\n",
      "84/84 [==============================] - 0s 767us/step - loss: 14.7203 - mse: 14.7203\n",
      "Epoch 10/100\n",
      "84/84 [==============================] - 0s 781us/step - loss: 10.8621 - mse: 10.8621\n",
      "Epoch 11/100\n",
      "84/84 [==============================] - 0s 738us/step - loss: 47.4504 - mse: 47.4504\n",
      "Epoch 12/100\n",
      "84/84 [==============================] - 0s 732us/step - loss: 21.3399 - mse: 21.3399\n",
      "Epoch 13/100\n",
      "84/84 [==============================] - 0s 787us/step - loss: 5.0141 - mse: 5.0141\n",
      "Epoch 14/100\n",
      "84/84 [==============================] - 0s 710us/step - loss: 7.1868 - mse: 7.1868\n",
      "Epoch 15/100\n",
      "84/84 [==============================] - 0s 726us/step - loss: 47.5799 - mse: 47.5799\n",
      "Epoch 16/100\n",
      "84/84 [==============================] - 0s 731us/step - loss: 42.5649 - mse: 42.5649\n",
      "Epoch 17/100\n",
      "84/84 [==============================] - 0s 708us/step - loss: 81.4762 - mse: 81.4762\n",
      "Epoch 18/100\n",
      "84/84 [==============================] - 0s 690us/step - loss: 16.5766 - mse: 16.5766\n",
      "Epoch 19/100\n",
      "84/84 [==============================] - 0s 740us/step - loss: 8.6766 - mse: 8.6766\n",
      "Epoch 20/100\n",
      "84/84 [==============================] - 0s 660us/step - loss: 42.2105 - mse: 42.2105\n",
      "Epoch 21/100\n",
      "84/84 [==============================] - 0s 706us/step - loss: 61.1204 - mse: 61.1204\n",
      "Epoch 22/100\n",
      "84/84 [==============================] - 0s 709us/step - loss: 48.8794 - mse: 48.8794\n",
      "Epoch 23/100\n",
      "84/84 [==============================] - 0s 685us/step - loss: 24.7455 - mse: 24.7455\n",
      "Epoch 24/100\n",
      "84/84 [==============================] - 0s 689us/step - loss: 95.2046 - mse: 95.2046\n",
      "Epoch 25/100\n",
      "84/84 [==============================] - 0s 718us/step - loss: 123.8988 - mse: 123.8988\n",
      "Epoch 26/100\n",
      "84/84 [==============================] - 0s 730us/step - loss: 21.7220 - mse: 21.7220\n",
      "Epoch 27/100\n",
      "84/84 [==============================] - 0s 736us/step - loss: 20.3452 - mse: 20.3452\n",
      "Epoch 28/100\n",
      "84/84 [==============================] - 0s 707us/step - loss: 48.3941 - mse: 48.3941\n",
      "Epoch 29/100\n",
      "84/84 [==============================] - 0s 756us/step - loss: 128.7193 - mse: 128.7193\n",
      "Epoch 30/100\n",
      "84/84 [==============================] - 0s 689us/step - loss: 297.9799 - mse: 297.9799\n",
      "Epoch 31/100\n",
      "84/84 [==============================] - 0s 730us/step - loss: 11.8068 - mse: 11.8068\n",
      "Epoch 32/100\n",
      "84/84 [==============================] - 0s 691us/step - loss: 8.5844 - mse: 8.5844\n",
      "Epoch 33/100\n",
      "84/84 [==============================] - 0s 660us/step - loss: 4.2768 - mse: 4.2768\n",
      "Epoch 34/100\n",
      "84/84 [==============================] - 0s 678us/step - loss: 64.6236 - mse: 64.6236\n",
      "Epoch 35/100\n",
      "84/84 [==============================] - 0s 685us/step - loss: 9.4631 - mse: 9.4631\n",
      "Epoch 36/100\n",
      "84/84 [==============================] - 0s 739us/step - loss: 70.7181 - mse: 70.7181\n",
      "Epoch 37/100\n",
      "84/84 [==============================] - 0s 698us/step - loss: 148.3247 - mse: 148.3247\n",
      "Epoch 38/100\n",
      "84/84 [==============================] - 0s 743us/step - loss: 88.5905 - mse: 88.5905\n",
      "Epoch 39/100\n",
      "84/84 [==============================] - 0s 743us/step - loss: 43.3967 - mse: 43.3967\n",
      "Epoch 40/100\n",
      "84/84 [==============================] - 0s 714us/step - loss: 37.5738 - mse: 37.5738\n",
      "Epoch 41/100\n",
      "84/84 [==============================] - 0s 731us/step - loss: 103.2280 - mse: 103.2280\n",
      "Epoch 42/100\n",
      "84/84 [==============================] - 0s 683us/step - loss: 27.9578 - mse: 27.9578\n",
      "Epoch 43/100\n",
      "84/84 [==============================] - 0s 710us/step - loss: 11.8134 - mse: 11.8134\n",
      "Epoch 44/100\n",
      "84/84 [==============================] - 0s 683us/step - loss: 13.6743 - mse: 13.6743\n",
      "Epoch 45/100\n",
      "84/84 [==============================] - 0s 728us/step - loss: 182.1296 - mse: 182.1296\n",
      "Epoch 46/100\n",
      "84/84 [==============================] - 0s 710us/step - loss: 39.3536 - mse: 39.3536\n",
      "Epoch 47/100\n",
      "84/84 [==============================] - 0s 877us/step - loss: 28.2978 - mse: 28.2978\n",
      "Epoch 48/100\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 46.1036 - mse: 46.1036\n",
      "Epoch 49/100\n",
      "84/84 [==============================] - 0s 969us/step - loss: 74.9539 - mse: 74.9540\n",
      "Epoch 50/100\n",
      "84/84 [==============================] - 0s 978us/step - loss: 24.9164 - mse: 24.9164\n",
      "Epoch 51/100\n",
      "84/84 [==============================] - 0s 863us/step - loss: 15.3523 - mse: 15.3523\n",
      "Epoch 52/100\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 4.1380 - mse: 4.1380\n",
      "Epoch 53/100\n",
      "84/84 [==============================] - 0s 925us/step - loss: 28.0112 - mse: 28.0112\n",
      "Epoch 54/100\n",
      "84/84 [==============================] - 0s 895us/step - loss: 68.2101 - mse: 68.2101\n",
      "Epoch 55/100\n",
      "84/84 [==============================] - 0s 991us/step - loss: 25.1188 - mse: 25.1188\n",
      "Epoch 56/100\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 21.7333 - mse: 21.7333\n",
      "Epoch 57/100\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 156.8600 - mse: 156.8600\n",
      "Epoch 58/100\n",
      "84/84 [==============================] - 0s 893us/step - loss: 39.0779 - mse: 39.0779\n",
      "Epoch 59/100\n",
      "84/84 [==============================] - 0s 923us/step - loss: 53.4298 - mse: 53.4298\n",
      "Epoch 60/100\n",
      "84/84 [==============================] - 0s 919us/step - loss: 159.7192 - mse: 159.7192\n",
      "Epoch 61/100\n",
      "84/84 [==============================] - 0s 956us/step - loss: 4.9774 - mse: 4.9774\n",
      "Epoch 62/100\n",
      "84/84 [==============================] - 0s 831us/step - loss: 106.6418 - mse: 106.6418\n",
      "Epoch 63/100\n",
      "84/84 [==============================] - 0s 829us/step - loss: 54.5109 - mse: 54.5109\n",
      "Epoch 64/100\n",
      "84/84 [==============================] - 0s 839us/step - loss: 22.1657 - mse: 22.1657\n",
      "Epoch 65/100\n",
      "84/84 [==============================] - 0s 881us/step - loss: 50.7817 - mse: 50.7817\n",
      "Epoch 66/100\n",
      "84/84 [==============================] - 0s 756us/step - loss: 86.5156 - mse: 86.5156\n",
      "Epoch 67/100\n",
      "84/84 [==============================] - 0s 773us/step - loss: 124.0454 - mse: 124.0454\n",
      "Epoch 68/100\n",
      "84/84 [==============================] - 0s 841us/step - loss: 25.3217 - mse: 25.3217\n",
      "Epoch 69/100\n",
      "84/84 [==============================] - 0s 949us/step - loss: 67.4081 - mse: 67.4081\n",
      "Epoch 70/100\n",
      "84/84 [==============================] - 0s 810us/step - loss: 134.5742 - mse: 134.5742\n",
      "Epoch 71/100\n",
      "84/84 [==============================] - 0s 864us/step - loss: 10.6051 - mse: 10.6051\n",
      "Epoch 72/100\n",
      "84/84 [==============================] - 0s 854us/step - loss: 110.1999 - mse: 110.1999\n",
      "Epoch 73/100\n",
      "84/84 [==============================] - 0s 904us/step - loss: 133.7015 - mse: 133.7015\n",
      "Epoch 74/100\n",
      "84/84 [==============================] - 0s 850us/step - loss: 14.9905 - mse: 14.9905\n",
      "Epoch 75/100\n",
      "84/84 [==============================] - 0s 790us/step - loss: 153.9697 - mse: 153.9697\n",
      "Epoch 76/100\n",
      "84/84 [==============================] - 0s 882us/step - loss: 253.8346 - mse: 253.8346\n",
      "Epoch 77/100\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 12.1135 - mse: 12.1135\n",
      "Epoch 78/100\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 42.6789 - mse: 42.6789\n",
      "Epoch 79/100\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 98.2711 - mse: 98.2711\n",
      "Epoch 80/100\n",
      "84/84 [==============================] - 0s 975us/step - loss: 94.7787 - mse: 94.7787\n",
      "Epoch 81/100\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 248.0440 - mse: 248.0440\n",
      "Epoch 82/100\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 2.7669 - mse: 2.7669\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 920us/step - loss: 12.5054 - mse: 12.5054\n",
      "Epoch 84/100\n",
      "84/84 [==============================] - 0s 955us/step - loss: 36.0667 - mse: 36.0667\n",
      "Epoch 85/100\n",
      "84/84 [==============================] - 0s 964us/step - loss: 24.3540 - mse: 24.3540\n",
      "Epoch 86/100\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 89.7117 - mse: 89.7117\n",
      "Epoch 87/100\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 29.4496 - mse: 29.4496\n",
      "Epoch 88/100\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 91.0110 - mse: 91.0110\n",
      "Epoch 89/100\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 24.5250 - mse: 24.5250\n",
      "Epoch 90/100\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 48.9969 - mse: 48.9969\n",
      "Epoch 91/100\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 11.3183 - mse: 11.3183\n",
      "Epoch 92/100\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 37.0814 - mse: 37.0814\n",
      "Epoch 93/100\n",
      "84/84 [==============================] - 0s 970us/step - loss: 46.4773 - mse: 46.4773\n",
      "Epoch 94/100\n",
      "84/84 [==============================] - 0s 951us/step - loss: 89.2200 - mse: 89.2200\n",
      "Epoch 95/100\n",
      "84/84 [==============================] - 0s 925us/step - loss: 7.5407 - mse: 7.5407\n",
      "Epoch 96/100\n",
      "84/84 [==============================] - 0s 926us/step - loss: 225.8059 - mse: 225.8059\n",
      "Epoch 97/100\n",
      "84/84 [==============================] - 0s 879us/step - loss: 21.4138 - mse: 21.4138\n",
      "Epoch 98/100\n",
      "84/84 [==============================] - 0s 870us/step - loss: 9.1274 - mse: 9.1274\n",
      "Epoch 99/100\n",
      "84/84 [==============================] - 0s 923us/step - loss: 37.7538 - mse: 37.7538\n",
      "Epoch 100/100\n",
      "84/84 [==============================] - 0s 968us/step - loss: 26.0046 - mse: 26.0046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f90c5657310>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Feature Scaling/preprocessing - normalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Building model\n",
    "model = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "model.add(Dense(8, activation = 'relu', input_dim = 40))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "model.add(Dense(units = 16, activation = 'relu'))\n",
    "\n",
    "#avoids overfitting\n",
    "#https://keras.io/api/layers/regularization_layers/dropout/\n",
    "model.add(keras.layers.Dropout(0.1))\n",
    "\n",
    "\n",
    "# Adding the output layer\n",
    "\n",
    "model.add(Dense(units = 1))\n",
    "\n",
    "\n",
    "# Compiling the ANN\n",
    "history=model.compile(optimizer = 'adam', loss = 'mse', metrics=['mse'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "model.fit(X_train, y_train, batch_size = 10, epochs = 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters involved:\n",
    "    https://keras.io/api/models/model_training_apis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 1ms/step - loss: 10.1810 - mse: 10.1810\n"
     ]
    }
   ],
   "source": [
    "#model evaluation\n",
    "mse = model.evaluate(X_test, y_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE without tuning: 10.180956840515137\n"
     ]
    }
   ],
   "source": [
    "print('MSE without tuning: {}'.format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 8)                 328       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 489\n",
      "Trainable params: 489\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://keras.io/api/models/sequential/\n",
    "The Sequential Class, provides a training and inference features on this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "plt.plot(y_test, color = 'red', label = 'Real data')\n",
    "plt.plot(y_pred, color = 'blue', label = 'Predicted data')\n",
    "plt.title('Prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cite: https://stackoverflow.com/questions/49008074/how-to-create-a-neural-network-for-regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 1.0833932640086255\n",
      "Mean Squared Error: 10.180958248780529\n",
      "Root Mean Squared Error: 3.1907613901356724\n"
     ]
    }
   ],
   "source": [
    "#Why are my errors all of a sudden so because of overfitting?\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kerastuner\n",
    "from kerastuner import HyperModel\n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(\n",
    "        units=hp.Int('units', min_value=8, max_value=32, step=4), \n",
    "        activation = hp.Choice('dense_activation', \n",
    "                values=['relu', 'tanh','sigmoid']),#,'softmax']),\n",
    "        input_dim = 40\n",
    "        )\n",
    "             \n",
    "    )\n",
    "\n",
    "    model.add(Dense(\n",
    "        units=hp.Int('units', min_value=8, max_value=32, step=4), \n",
    "        activation = hp.Choice('dense_activation', \n",
    "                values=['relu', 'tanh','sigmoid'])#,'softmax'])\n",
    "        )\n",
    "             \n",
    "    )\n",
    "    \n",
    "    model.add(\n",
    "        keras.layers.Dropout(\n",
    "            hp.Float(\n",
    "                    'dropout',\n",
    "                    min_value=0.0,\n",
    "                    max_value=0.1,\n",
    "                    step=0.01)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Adding the output layer\n",
    "    model.add(Dense(units = 1))\n",
    "\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        #optimizer = hp.Choice('dense_optimizer',\n",
    "                #values=['adam','SGD','rmsprop','adadelta'] ),\n",
    "        loss = 'mse',\n",
    "        metrics = ['mse']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "tuner_rs = kerastuner.tuners.RandomSearch(\n",
    "            build_model,\n",
    "            objective='mse',\n",
    "            max_trials=5,\n",
    "            executions_per_trial=2, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner_rs.search(X_train, y_train, epochs=10) #, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0706 - mse: 1.0706\n"
     ]
    }
   ],
   "source": [
    "best_model = tuner_rs.get_best_models(num_models=1)[0]\n",
    "mse_rs = best_model.evaluate(X_test, y_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 968us/step - loss: 1.1320 - mse: 1.1320\n"
     ]
    }
   ],
   "source": [
    "loss, mse = best_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in ./untitled_project\n",
      "Showing 10 best trials\n",
      "Objective(name='mse', direction='min')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 32\n",
      "dense_activation: tanh\n",
      "dropout: 0.1\n",
      "Score: 62.28594207763672\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 24\n",
      "dense_activation: tanh\n",
      "dropout: 0.1\n",
      "Score: 62.45891189575195\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 16\n",
      "dense_activation: tanh\n",
      "dropout: 0.08\n",
      "Score: 62.59344482421875\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 24\n",
      "dense_activation: sigmoid\n",
      "dropout: 0.01\n",
      "Score: 62.96743965148926\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 16\n",
      "dense_activation: sigmoid\n",
      "dropout: 0.07\n",
      "Score: 63.06424140930176\n"
     ]
    }
   ],
   "source": [
    "tuner_rs.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
