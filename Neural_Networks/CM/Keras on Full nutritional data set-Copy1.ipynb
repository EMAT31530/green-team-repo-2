{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Cam/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/Cam/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/Cam/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/Cam/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/Cam/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/Cam/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/Cam/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/Cam/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/Cam/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/Cam/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/Cam/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/Cam/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "import tensorflow\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>Food Group</th>\n",
       "      <th>Price (£)</th>\n",
       "      <th>Weight (GRAMS)</th>\n",
       "      <th>Price per Weight (£/100Gram)</th>\n",
       "      <th>Carbon Group</th>\n",
       "      <th>Land use (m2/100g)</th>\n",
       "      <th>GHG(kgco2eq/100g)</th>\n",
       "      <th>Water use (L/100g)</th>\n",
       "      <th>Acidifying emissions(kgSO2eq per 100g)</th>\n",
       "      <th>...</th>\n",
       "      <th>Carotene, alpha (mcg)</th>\n",
       "      <th>Lycopene (mcg)</th>\n",
       "      <th>Lutein + Zeaxanthin (mcg)</th>\n",
       "      <th>Fatty acids, total monounsaturated (mg)</th>\n",
       "      <th>Fatty acids, total polyunsaturated (mg)</th>\n",
       "      <th>20:5 n-3 (EPA) (mg)</th>\n",
       "      <th>22:5 n-3 (DPA) (mg)</th>\n",
       "      <th>22:6 n-3 (DHA) (mg)</th>\n",
       "      <th>Caffeine (mg)</th>\n",
       "      <th>Theobromine (mg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Waffles Buttermilk Frozen Ready-To-Heat</td>\n",
       "      <td>Baked Foods</td>\n",
       "      <td>1.50</td>\n",
       "      <td>567.0</td>\n",
       "      <td>0.264550</td>\n",
       "      <td>Bread products</td>\n",
       "      <td>0.3482</td>\n",
       "      <td>0.1441</td>\n",
       "      <td>56.7</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>4530.0</td>\n",
       "      <td>1445.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Waffle Buttermilk Frozen Ready-To-Heat Toasted</td>\n",
       "      <td>Baked Foods</td>\n",
       "      <td>1.50</td>\n",
       "      <td>567.0</td>\n",
       "      <td>0.264550</td>\n",
       "      <td>Bread products</td>\n",
       "      <td>0.3482</td>\n",
       "      <td>0.1441</td>\n",
       "      <td>56.7</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>5292.0</td>\n",
       "      <td>1502.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dutch Apple Pie</td>\n",
       "      <td>Baked Foods</td>\n",
       "      <td>2.80</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>Bread products</td>\n",
       "      <td>0.3482</td>\n",
       "      <td>0.1441</td>\n",
       "      <td>56.7</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5797.0</td>\n",
       "      <td>2117.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bread White Wheat</td>\n",
       "      <td>Baked Foods</td>\n",
       "      <td>0.95</td>\n",
       "      <td>800.0</td>\n",
       "      <td>0.118750</td>\n",
       "      <td>Bread products</td>\n",
       "      <td>0.3482</td>\n",
       "      <td>0.1441</td>\n",
       "      <td>56.7</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>973.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bagels Wheat</td>\n",
       "      <td>Baked Foods</td>\n",
       "      <td>1.60</td>\n",
       "      <td>450.0</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>Bread products</td>\n",
       "      <td>0.3482</td>\n",
       "      <td>0.1441</td>\n",
       "      <td>56.7</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>936.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>Plantain Fried</td>\n",
       "      <td>Vegetables</td>\n",
       "      <td>0.90</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.058824</td>\n",
       "      <td>Other vegetables</td>\n",
       "      <td>0.0310</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>...</td>\n",
       "      <td>418.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4099.0</td>\n",
       "      <td>4079.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>Romaine Lettuce Raw</td>\n",
       "      <td>Vegetables</td>\n",
       "      <td>1.00</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>Other vegetables</td>\n",
       "      <td>0.0310</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4204.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>Palak Paneer</td>\n",
       "      <td>Vegetables</td>\n",
       "      <td>3.75</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>Cheese</td>\n",
       "      <td>8.0642</td>\n",
       "      <td>2.1240</td>\n",
       "      <td>473.5</td>\n",
       "      <td>0.014894</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>4097.0</td>\n",
       "      <td>2402.0</td>\n",
       "      <td>2112.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>Carrots Raw Salad</td>\n",
       "      <td>Vegetables</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.041000</td>\n",
       "      <td>Other vegetables</td>\n",
       "      <td>0.0310</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>...</td>\n",
       "      <td>2157.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>3498.0</td>\n",
       "      <td>9319.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>Corn on the cob</td>\n",
       "      <td>Vegetables</td>\n",
       "      <td>1.50</td>\n",
       "      <td>875.0</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>Other vegetables</td>\n",
       "      <td>0.0310</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>693.0</td>\n",
       "      <td>373.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1042 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name   Food Group  Price (£)  \\\n",
       "1            Waffles Buttermilk Frozen Ready-To-Heat  Baked Foods       1.50   \n",
       "2     Waffle Buttermilk Frozen Ready-To-Heat Toasted  Baked Foods       1.50   \n",
       "5                                    Dutch Apple Pie  Baked Foods       2.80   \n",
       "9                                  Bread White Wheat  Baked Foods       0.95   \n",
       "10                                      Bagels Wheat  Baked Foods       1.60   \n",
       "...                                              ...          ...        ...   \n",
       "1218                                 Plantain Fried    Vegetables       0.90   \n",
       "1219                             Romaine Lettuce Raw   Vegetables       1.00   \n",
       "1220                                    Palak Paneer   Vegetables       3.75   \n",
       "1221                               Carrots Raw Salad   Vegetables       0.41   \n",
       "1222                                Corn on the cob    Vegetables       1.50   \n",
       "\n",
       "      Weight (GRAMS)  Price per Weight (£/100Gram)       Carbon Group  \\\n",
       "1              567.0                      0.264550    Bread products    \n",
       "2              567.0                      0.264550    Bread products    \n",
       "5              500.0                      0.560000    Bread products    \n",
       "9              800.0                      0.118750    Bread products    \n",
       "10             450.0                      0.355556    Bread products    \n",
       "...              ...                           ...                ...   \n",
       "1218            85.0                      1.058824  Other vegetables    \n",
       "1219           400.0                      0.250000  Other vegetables    \n",
       "1220           500.0                      0.750000            Cheese    \n",
       "1221          1000.0                      0.041000  Other vegetables    \n",
       "1222           875.0                      0.171429  Other vegetables    \n",
       "\n",
       "      Land use (m2/100g)  GHG(kgco2eq/100g)  Water use (L/100g)  \\\n",
       "1                 0.3482             0.1441                56.7   \n",
       "2                 0.3482             0.1441                56.7   \n",
       "5                 0.3482             0.1441                56.7   \n",
       "9                 0.3482             0.1441                56.7   \n",
       "10                0.3482             0.1441                56.7   \n",
       "...                  ...                ...                 ...   \n",
       "1218              0.0310             0.0455                 8.3   \n",
       "1219              0.0310             0.0455                 8.3   \n",
       "1220              8.0642             2.1240               473.5   \n",
       "1221              0.0310             0.0455                 8.3   \n",
       "1222              0.0310             0.0455                 8.3   \n",
       "\n",
       "      Acidifying emissions(kgSO2eq per 100g)  ...  Carotene, alpha (mcg)  \\\n",
       "1                                   0.001209  ...                    0.0   \n",
       "2                                   0.001209  ...                    0.0   \n",
       "5                                   0.001209  ...                    0.0   \n",
       "9                                   0.001209  ...                    0.0   \n",
       "10                                  0.001209  ...                    0.0   \n",
       "...                                      ...  ...                    ...   \n",
       "1218                                0.000531  ...                  418.0   \n",
       "1219                                0.000531  ...                    0.0   \n",
       "1220                                0.014894  ...                   12.0   \n",
       "1221                                0.000531  ...                 2157.0   \n",
       "1222                                0.000531  ...                    6.0   \n",
       "\n",
       "      Lycopene (mcg)  Lutein + Zeaxanthin (mcg)  \\\n",
       "1                0.0                       63.0   \n",
       "2                0.0                       66.0   \n",
       "5                1.0                       42.0   \n",
       "9                0.0                       25.0   \n",
       "10               0.0                       88.0   \n",
       "...              ...                        ...   \n",
       "1218             0.0                       29.0   \n",
       "1219             0.0                     4204.0   \n",
       "1220           313.0                     4097.0   \n",
       "1221             1.0                      162.0   \n",
       "1222             0.0                      693.0   \n",
       "\n",
       "      Fatty acids, total monounsaturated (mg)  \\\n",
       "1                                      4530.0   \n",
       "2                                      5292.0   \n",
       "5                                      5797.0   \n",
       "9                                       393.0   \n",
       "10                                      290.0   \n",
       "...                                       ...   \n",
       "1218                                   4099.0   \n",
       "1219                                      7.0   \n",
       "1220                                   2402.0   \n",
       "1221                                   3498.0   \n",
       "1222                                    373.0   \n",
       "\n",
       "      Fatty acids, total polyunsaturated (mg)  20:5 n-3 (EPA) (mg)  \\\n",
       "1                                      1445.0                 12.0   \n",
       "2                                      1502.0                 13.0   \n",
       "5                                      2117.0                  0.0   \n",
       "9                                       973.0                  3.0   \n",
       "10                                      936.0                  0.0   \n",
       "...                                       ...                  ...   \n",
       "1218                                   4079.0                  0.0   \n",
       "1219                                    126.0                  0.0   \n",
       "1220                                   2112.0                  0.0   \n",
       "1221                                   9319.0                  0.0   \n",
       "1222                                    518.0                  0.0   \n",
       "\n",
       "      22:5 n-3 (DPA) (mg)  22:6 n-3 (DHA) (mg)  Caffeine (mg)  \\\n",
       "1                     0.0                  7.0            0.0   \n",
       "2                     0.0                  8.0            0.0   \n",
       "5                     0.0                  0.0            0.0   \n",
       "9                     0.0                  0.0            0.0   \n",
       "10                    0.0                  0.0            0.0   \n",
       "...                   ...                  ...            ...   \n",
       "1218                  0.0                  0.0            0.0   \n",
       "1219                  0.0                  0.0            0.0   \n",
       "1220                  0.0                  0.0            0.0   \n",
       "1221                  0.0                  1.0            0.0   \n",
       "1222                  0.0                  0.0            0.0   \n",
       "\n",
       "      Theobromine (mg)  \n",
       "1                  0.0  \n",
       "2                  0.0  \n",
       "5                  0.0  \n",
       "9                  0.0  \n",
       "10                 0.0  \n",
       "...                ...  \n",
       "1218               0.0  \n",
       "1219               0.0  \n",
       "1220               0.0  \n",
       "1221               0.0  \n",
       "1222               0.0  \n",
       "\n",
       "[1042 rows x 51 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nutrition = pd.read_pickle(\"./Nutrition_Full_Features.pkl\")\n",
    "nutrition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data for features\n",
    "X = nutrition.iloc[:, 11:] # nutritional values, predictors\n",
    "y = nutrition.iloc[:, 7] # carbon content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Calories</th>\n",
       "      <th>Fat (g)</th>\n",
       "      <th>Protein (g)</th>\n",
       "      <th>Carbohydrate (g)</th>\n",
       "      <th>Sugars (g)</th>\n",
       "      <th>Fiber (g)</th>\n",
       "      <th>Saturated Fats (g)</th>\n",
       "      <th>Calcium (mg)</th>\n",
       "      <th>Iron, Fe (mg)</th>\n",
       "      <th>Potassium, K (mg)</th>\n",
       "      <th>...</th>\n",
       "      <th>Carotene, alpha (mcg)</th>\n",
       "      <th>Lycopene (mcg)</th>\n",
       "      <th>Lutein + Zeaxanthin (mcg)</th>\n",
       "      <th>Fatty acids, total monounsaturated (mg)</th>\n",
       "      <th>Fatty acids, total polyunsaturated (mg)</th>\n",
       "      <th>20:5 n-3 (EPA) (mg)</th>\n",
       "      <th>22:5 n-3 (DPA) (mg)</th>\n",
       "      <th>22:6 n-3 (DHA) (mg)</th>\n",
       "      <th>Caffeine (mg)</th>\n",
       "      <th>Theobromine (mg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>273</td>\n",
       "      <td>9.22</td>\n",
       "      <td>6.58</td>\n",
       "      <td>41.05</td>\n",
       "      <td>4.30</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.898</td>\n",
       "      <td>279</td>\n",
       "      <td>6.04</td>\n",
       "      <td>126.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>4530.0</td>\n",
       "      <td>1445.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>309</td>\n",
       "      <td>9.49</td>\n",
       "      <td>7.42</td>\n",
       "      <td>48.39</td>\n",
       "      <td>4.41</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.275</td>\n",
       "      <td>299</td>\n",
       "      <td>6.59</td>\n",
       "      <td>138.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>5292.0</td>\n",
       "      <td>1502.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>290</td>\n",
       "      <td>11.50</td>\n",
       "      <td>2.17</td>\n",
       "      <td>44.54</td>\n",
       "      <td>22.02</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.313</td>\n",
       "      <td>14</td>\n",
       "      <td>0.91</td>\n",
       "      <td>76.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5797.0</td>\n",
       "      <td>2117.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>238</td>\n",
       "      <td>2.15</td>\n",
       "      <td>10.66</td>\n",
       "      <td>43.91</td>\n",
       "      <td>5.00</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.630</td>\n",
       "      <td>684</td>\n",
       "      <td>4.89</td>\n",
       "      <td>127.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>973.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>250</td>\n",
       "      <td>1.53</td>\n",
       "      <td>10.20</td>\n",
       "      <td>48.89</td>\n",
       "      <td>6.12</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>20</td>\n",
       "      <td>2.76</td>\n",
       "      <td>165.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>936.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>241</td>\n",
       "      <td>10.16</td>\n",
       "      <td>1.66</td>\n",
       "      <td>40.60</td>\n",
       "      <td>19.10</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.507</td>\n",
       "      <td>4</td>\n",
       "      <td>0.78</td>\n",
       "      <td>572.0</td>\n",
       "      <td>...</td>\n",
       "      <td>418.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4099.0</td>\n",
       "      <td>4079.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>19</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.39</td>\n",
       "      <td>3.78</td>\n",
       "      <td>0.71</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.053</td>\n",
       "      <td>62</td>\n",
       "      <td>0.90</td>\n",
       "      <td>327.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4204.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>96</td>\n",
       "      <td>6.84</td>\n",
       "      <td>5.23</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.486</td>\n",
       "      <td>70</td>\n",
       "      <td>1.15</td>\n",
       "      <td>269.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>4097.0</td>\n",
       "      <td>2402.0</td>\n",
       "      <td>2112.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>208</td>\n",
       "      <td>15.70</td>\n",
       "      <td>1.22</td>\n",
       "      <td>17.17</td>\n",
       "      <td>11.23</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.452</td>\n",
       "      <td>30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>309.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2157.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>3498.0</td>\n",
       "      <td>9319.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>67</td>\n",
       "      <td>1.22</td>\n",
       "      <td>2.28</td>\n",
       "      <td>14.30</td>\n",
       "      <td>4.43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.244</td>\n",
       "      <td>3</td>\n",
       "      <td>0.27</td>\n",
       "      <td>132.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>693.0</td>\n",
       "      <td>373.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1042 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Calories  Fat (g)  Protein (g)  Carbohydrate (g)  Sugars (g)  Fiber (g)  \\\n",
       "1          273     9.22         6.58             41.05        4.30        2.2   \n",
       "2          309     9.49         7.42             48.39        4.41        2.6   \n",
       "5          290    11.50         2.17             44.54       22.02        1.6   \n",
       "9          238     2.15        10.66             43.91        5.00        9.2   \n",
       "10         250     1.53        10.20             48.89        6.12        4.1   \n",
       "...        ...      ...          ...               ...         ...        ...   \n",
       "1218       241    10.16         1.66             40.60       19.10        2.9   \n",
       "1219        19     0.27         1.39              3.78        0.71        3.1   \n",
       "1220        96     6.84         5.23              4.32        1.89        1.2   \n",
       "1221       208    15.70         1.22             17.17       11.23        2.3   \n",
       "1222        67     1.22         2.28             14.30        4.43        2.0   \n",
       "\n",
       "      Saturated Fats (g)  Calcium (mg)  Iron, Fe (mg)  Potassium, K (mg)  ...  \\\n",
       "1                  1.898           279           6.04              126.0  ...   \n",
       "2                  2.275           299           6.59              138.0  ...   \n",
       "5                  2.313            14           0.91               76.0  ...   \n",
       "9                  0.630           684           4.89              127.0  ...   \n",
       "10                 0.000            20           2.76              165.0  ...   \n",
       "...                  ...           ...            ...                ...  ...   \n",
       "1218               1.507             4           0.78              572.0  ...   \n",
       "1219               0.053            62           0.90              327.0  ...   \n",
       "1220               1.486            70           1.15              269.0  ...   \n",
       "1221               2.452            30           0.49              309.0  ...   \n",
       "1222               0.244             3           0.27              132.0  ...   \n",
       "\n",
       "      Carotene, alpha (mcg)  Lycopene (mcg)  Lutein + Zeaxanthin (mcg)  \\\n",
       "1                       0.0             0.0                       63.0   \n",
       "2                       0.0             0.0                       66.0   \n",
       "5                       0.0             1.0                       42.0   \n",
       "9                       0.0             0.0                       25.0   \n",
       "10                      0.0             0.0                       88.0   \n",
       "...                     ...             ...                        ...   \n",
       "1218                  418.0             0.0                       29.0   \n",
       "1219                    0.0             0.0                     4204.0   \n",
       "1220                   12.0           313.0                     4097.0   \n",
       "1221                 2157.0             1.0                      162.0   \n",
       "1222                    6.0             0.0                      693.0   \n",
       "\n",
       "      Fatty acids, total monounsaturated (mg)  \\\n",
       "1                                      4530.0   \n",
       "2                                      5292.0   \n",
       "5                                      5797.0   \n",
       "9                                       393.0   \n",
       "10                                      290.0   \n",
       "...                                       ...   \n",
       "1218                                   4099.0   \n",
       "1219                                      7.0   \n",
       "1220                                   2402.0   \n",
       "1221                                   3498.0   \n",
       "1222                                    373.0   \n",
       "\n",
       "      Fatty acids, total polyunsaturated (mg)  20:5 n-3 (EPA) (mg)  \\\n",
       "1                                      1445.0                 12.0   \n",
       "2                                      1502.0                 13.0   \n",
       "5                                      2117.0                  0.0   \n",
       "9                                       973.0                  3.0   \n",
       "10                                      936.0                  0.0   \n",
       "...                                       ...                  ...   \n",
       "1218                                   4079.0                  0.0   \n",
       "1219                                    126.0                  0.0   \n",
       "1220                                   2112.0                  0.0   \n",
       "1221                                   9319.0                  0.0   \n",
       "1222                                    518.0                  0.0   \n",
       "\n",
       "      22:5 n-3 (DPA) (mg)  22:6 n-3 (DHA) (mg)  Caffeine (mg)  \\\n",
       "1                     0.0                  7.0            0.0   \n",
       "2                     0.0                  8.0            0.0   \n",
       "5                     0.0                  0.0            0.0   \n",
       "9                     0.0                  0.0            0.0   \n",
       "10                    0.0                  0.0            0.0   \n",
       "...                   ...                  ...            ...   \n",
       "1218                  0.0                  0.0            0.0   \n",
       "1219                  0.0                  0.0            0.0   \n",
       "1220                  0.0                  0.0            0.0   \n",
       "1221                  0.0                  1.0            0.0   \n",
       "1222                  0.0                  0.0            0.0   \n",
       "\n",
       "      Theobromine (mg)  \n",
       "1                  0.0  \n",
       "2                  0.0  \n",
       "5                  0.0  \n",
       "9                  0.0  \n",
       "10                 0.0  \n",
       "...                ...  \n",
       "1218               0.0  \n",
       "1219               0.0  \n",
       "1220               0.0  \n",
       "1221               0.0  \n",
       "1222               0.0  \n",
       "\n",
       "[1042 rows x 40 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1       0.1441\n",
       "2       0.1441\n",
       "5       0.1441\n",
       "9       0.1441\n",
       "10      0.1441\n",
       "         ...  \n",
       "1218    0.0455\n",
       "1219    0.0455\n",
       "1220    2.1240\n",
       "1221    0.0455\n",
       "1222    0.0455\n",
       "Name: GHG(kgco2eq/100g), Length: 1042, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# command/\n",
    "#only normalising X not y. Is this right?\n",
    "# norm_X = preprocessing.normalize(X, axis=0) #collum instead of row\n",
    "# norm_X = pd.DataFrame(norm_X, columns = X.columns)\n",
    "# X=norm_X\n",
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.ravel(y)\n",
    "X = X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "833/833 [==============================] - 1s 2ms/step - loss: 3.0028 - mse: 3.0028\n",
      "Epoch 2/100\n",
      "833/833 [==============================] - 0s 382us/step - loss: 2.2406 - mse: 2.2406\n",
      "Epoch 3/100\n",
      "833/833 [==============================] - 0s 340us/step - loss: 1.8014 - mse: 1.8014\n",
      "Epoch 4/100\n",
      "833/833 [==============================] - 0s 356us/step - loss: 1.4971 - mse: 1.4971\n",
      "Epoch 5/100\n",
      "833/833 [==============================] - 0s 336us/step - loss: 1.3537 - mse: 1.3537\n",
      "Epoch 6/100\n",
      "833/833 [==============================] - 0s 346us/step - loss: 1.0853 - mse: 1.0853\n",
      "Epoch 7/100\n",
      "833/833 [==============================] - 0s 345us/step - loss: 0.9983 - mse: 0.9983\n",
      "Epoch 8/100\n",
      "833/833 [==============================] - 0s 343us/step - loss: 0.8460 - mse: 0.8460\n",
      "Epoch 9/100\n",
      "833/833 [==============================] - 0s 349us/step - loss: 0.7388 - mse: 0.7388\n",
      "Epoch 10/100\n",
      "833/833 [==============================] - 0s 340us/step - loss: 0.7264 - mse: 0.7264\n",
      "Epoch 11/100\n",
      "833/833 [==============================] - 0s 349us/step - loss: 0.7601 - mse: 0.7601\n",
      "Epoch 12/100\n",
      "833/833 [==============================] - 0s 358us/step - loss: 0.6222 - mse: 0.6222\n",
      "Epoch 13/100\n",
      "833/833 [==============================] - 0s 349us/step - loss: 0.5594 - mse: 0.5594\n",
      "Epoch 14/100\n",
      "833/833 [==============================] - 0s 340us/step - loss: 0.5600 - mse: 0.5600\n",
      "Epoch 15/100\n",
      "833/833 [==============================] - 0s 363us/step - loss: 0.5848 - mse: 0.5848\n",
      "Epoch 16/100\n",
      "833/833 [==============================] - 0s 423us/step - loss: 0.5657 - mse: 0.5657\n",
      "Epoch 17/100\n",
      "833/833 [==============================] - 0s 337us/step - loss: 0.5224 - mse: 0.5224\n",
      "Epoch 18/100\n",
      "833/833 [==============================] - 0s 347us/step - loss: 0.5782 - mse: 0.5782\n",
      "Epoch 19/100\n",
      "833/833 [==============================] - 0s 396us/step - loss: 0.4864 - mse: 0.4864\n",
      "Epoch 20/100\n",
      "833/833 [==============================] - 0s 388us/step - loss: 0.5078 - mse: 0.5078\n",
      "Epoch 21/100\n",
      "833/833 [==============================] - 0s 405us/step - loss: 0.4874 - mse: 0.4874\n",
      "Epoch 22/100\n",
      "833/833 [==============================] - 0s 361us/step - loss: 0.4502 - mse: 0.4502\n",
      "Epoch 23/100\n",
      "833/833 [==============================] - 0s 412us/step - loss: 0.4485 - mse: 0.4485\n",
      "Epoch 24/100\n",
      "833/833 [==============================] - 0s 356us/step - loss: 0.4665 - mse: 0.4665\n",
      "Epoch 25/100\n",
      "833/833 [==============================] - 0s 356us/step - loss: 0.3965 - mse: 0.3965\n",
      "Epoch 26/100\n",
      "833/833 [==============================] - 0s 374us/step - loss: 0.4543 - mse: 0.4543\n",
      "Epoch 27/100\n",
      "833/833 [==============================] - 0s 372us/step - loss: 0.4320 - mse: 0.4320\n",
      "Epoch 28/100\n",
      "833/833 [==============================] - 0s 410us/step - loss: 0.4076 - mse: 0.4076\n",
      "Epoch 29/100\n",
      "833/833 [==============================] - 0s 415us/step - loss: 0.3972 - mse: 0.3972\n",
      "Epoch 30/100\n",
      "833/833 [==============================] - 0s 337us/step - loss: 0.3611 - mse: 0.3611\n",
      "Epoch 31/100\n",
      "833/833 [==============================] - 0s 357us/step - loss: 0.3889 - mse: 0.3889\n",
      "Epoch 32/100\n",
      "833/833 [==============================] - 1s 781us/step - loss: 0.3723 - mse: 0.3723\n",
      "Epoch 33/100\n",
      "833/833 [==============================] - 0s 466us/step - loss: 0.3624 - mse: 0.3624\n",
      "Epoch 34/100\n",
      "833/833 [==============================] - 0s 410us/step - loss: 0.3907 - mse: 0.3907\n",
      "Epoch 35/100\n",
      "833/833 [==============================] - 0s 440us/step - loss: 0.3885 - mse: 0.3885\n",
      "Epoch 36/100\n",
      "833/833 [==============================] - 0s 424us/step - loss: 0.3728 - mse: 0.3728\n",
      "Epoch 37/100\n",
      "833/833 [==============================] - 0s 377us/step - loss: 0.3419 - mse: 0.3419\n",
      "Epoch 38/100\n",
      "833/833 [==============================] - 0s 414us/step - loss: 0.3712 - mse: 0.3712\n",
      "Epoch 39/100\n",
      "833/833 [==============================] - 0s 390us/step - loss: 0.3462 - mse: 0.3462\n",
      "Epoch 40/100\n",
      "833/833 [==============================] - 0s 392us/step - loss: 0.3388 - mse: 0.3388\n",
      "Epoch 41/100\n",
      "833/833 [==============================] - 0s 352us/step - loss: 0.3282 - mse: 0.3282\n",
      "Epoch 42/100\n",
      "833/833 [==============================] - 0s 345us/step - loss: 0.3341 - mse: 0.3341\n",
      "Epoch 43/100\n",
      "833/833 [==============================] - 0s 350us/step - loss: 0.3114 - mse: 0.3114\n",
      "Epoch 44/100\n",
      "833/833 [==============================] - 0s 338us/step - loss: 0.3176 - mse: 0.3176\n",
      "Epoch 45/100\n",
      "833/833 [==============================] - 0s 345us/step - loss: 0.3099 - mse: 0.3099\n",
      "Epoch 46/100\n",
      "833/833 [==============================] - 0s 362us/step - loss: 0.3507 - mse: 0.3507\n",
      "Epoch 47/100\n",
      "833/833 [==============================] - 0s 357us/step - loss: 0.3408 - mse: 0.3408\n",
      "Epoch 48/100\n",
      "833/833 [==============================] - 0s 357us/step - loss: 0.3066 - mse: 0.3066\n",
      "Epoch 49/100\n",
      "833/833 [==============================] - 0s 344us/step - loss: 0.3235 - mse: 0.3235\n",
      "Epoch 50/100\n",
      "833/833 [==============================] - 0s 379us/step - loss: 0.2887 - mse: 0.2887\n",
      "Epoch 51/100\n",
      "833/833 [==============================] - 0s 421us/step - loss: 0.3549 - mse: 0.3549\n",
      "Epoch 52/100\n",
      "833/833 [==============================] - 0s 357us/step - loss: 0.3127 - mse: 0.3127\n",
      "Epoch 53/100\n",
      "833/833 [==============================] - 0s 392us/step - loss: 0.3064 - mse: 0.3064\n",
      "Epoch 54/100\n",
      "833/833 [==============================] - 0s 347us/step - loss: 0.3461 - mse: 0.3461\n",
      "Epoch 55/100\n",
      "833/833 [==============================] - 0s 402us/step - loss: 0.2707 - mse: 0.2707\n",
      "Epoch 56/100\n",
      "833/833 [==============================] - 0s 360us/step - loss: 0.3037 - mse: 0.3037\n",
      "Epoch 57/100\n",
      "833/833 [==============================] - 0s 358us/step - loss: 0.2992 - mse: 0.2992\n",
      "Epoch 58/100\n",
      "833/833 [==============================] - 0s 327us/step - loss: 0.2916 - mse: 0.2916\n",
      "Epoch 59/100\n",
      "833/833 [==============================] - 0s 358us/step - loss: 0.3045 - mse: 0.3045\n",
      "Epoch 60/100\n",
      "833/833 [==============================] - 0s 371us/step - loss: 0.3071 - mse: 0.3071\n",
      "Epoch 61/100\n",
      "833/833 [==============================] - 0s 336us/step - loss: 0.2951 - mse: 0.2951\n",
      "Epoch 62/100\n",
      "833/833 [==============================] - 0s 341us/step - loss: 0.2660 - mse: 0.2660\n",
      "Epoch 63/100\n",
      "833/833 [==============================] - 0s 335us/step - loss: 0.3294 - mse: 0.3294\n",
      "Epoch 64/100\n",
      "833/833 [==============================] - 0s 334us/step - loss: 0.2565 - mse: 0.2565\n",
      "Epoch 65/100\n",
      "833/833 [==============================] - 0s 351us/step - loss: 0.2546 - mse: 0.2546\n",
      "Epoch 66/100\n",
      "833/833 [==============================] - 0s 350us/step - loss: 0.2924 - mse: 0.2924\n",
      "Epoch 67/100\n",
      "833/833 [==============================] - 0s 338us/step - loss: 0.2606 - mse: 0.2606\n",
      "Epoch 68/100\n",
      "833/833 [==============================] - 0s 359us/step - loss: 0.2577 - mse: 0.2577\n",
      "Epoch 69/100\n",
      "833/833 [==============================] - 0s 328us/step - loss: 0.2957 - mse: 0.2957\n",
      "Epoch 70/100\n",
      "833/833 [==============================] - 0s 338us/step - loss: 0.2577 - mse: 0.2577\n",
      "Epoch 71/100\n",
      "833/833 [==============================] - 0s 348us/step - loss: 0.2695 - mse: 0.2695\n",
      "Epoch 72/100\n",
      "833/833 [==============================] - 0s 356us/step - loss: 0.2770 - mse: 0.2770\n",
      "Epoch 73/100\n",
      "833/833 [==============================] - 0s 346us/step - loss: 0.2823 - mse: 0.2823\n",
      "Epoch 74/100\n",
      "833/833 [==============================] - 0s 358us/step - loss: 0.2725 - mse: 0.2725\n",
      "Epoch 75/100\n",
      "833/833 [==============================] - 0s 323us/step - loss: 0.2523 - mse: 0.2523\n",
      "Epoch 76/100\n",
      "833/833 [==============================] - 0s 364us/step - loss: 0.2402 - mse: 0.2402\n",
      "Epoch 77/100\n",
      "833/833 [==============================] - 0s 369us/step - loss: 0.2323 - mse: 0.2323\n",
      "Epoch 78/100\n",
      "833/833 [==============================] - 0s 372us/step - loss: 0.2517 - mse: 0.2517\n",
      "Epoch 79/100\n",
      "833/833 [==============================] - 0s 390us/step - loss: 0.2512 - mse: 0.2512\n",
      "Epoch 80/100\n",
      "833/833 [==============================] - 0s 438us/step - loss: 0.2456 - mse: 0.2456\n",
      "Epoch 81/100\n",
      "833/833 [==============================] - 0s 392us/step - loss: 0.2971 - mse: 0.2971\n",
      "Epoch 82/100\n",
      "833/833 [==============================] - 0s 368us/step - loss: 0.2639 - mse: 0.2639\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "833/833 [==============================] - 0s 337us/step - loss: 0.2378 - mse: 0.2378\n",
      "Epoch 84/100\n",
      "833/833 [==============================] - 0s 340us/step - loss: 0.2424 - mse: 0.2424\n",
      "Epoch 85/100\n",
      "833/833 [==============================] - 0s 347us/step - loss: 0.2336 - mse: 0.2336\n",
      "Epoch 86/100\n",
      "833/833 [==============================] - 0s 372us/step - loss: 0.2878 - mse: 0.2878\n",
      "Epoch 87/100\n",
      "833/833 [==============================] - 0s 364us/step - loss: 0.2362 - mse: 0.2362\n",
      "Epoch 88/100\n",
      "833/833 [==============================] - 0s 322us/step - loss: 0.2548 - mse: 0.2548\n",
      "Epoch 89/100\n",
      "833/833 [==============================] - 0s 312us/step - loss: 0.2352 - mse: 0.2352\n",
      "Epoch 90/100\n",
      "833/833 [==============================] - 0s 310us/step - loss: 0.2561 - mse: 0.2561\n",
      "Epoch 91/100\n",
      "833/833 [==============================] - 0s 366us/step - loss: 0.2718 - mse: 0.2718\n",
      "Epoch 92/100\n",
      "833/833 [==============================] - 0s 311us/step - loss: 0.2100 - mse: 0.2100\n",
      "Epoch 93/100\n",
      "833/833 [==============================] - 0s 302us/step - loss: 0.2108 - mse: 0.2108\n",
      "Epoch 94/100\n",
      "833/833 [==============================] - 0s 306us/step - loss: 0.2309 - mse: 0.2309\n",
      "Epoch 95/100\n",
      "833/833 [==============================] - 0s 310us/step - loss: 0.2251 - mse: 0.2251\n",
      "Epoch 96/100\n",
      "833/833 [==============================] - 0s 313us/step - loss: 0.2473 - mse: 0.2473\n",
      "Epoch 97/100\n",
      "833/833 [==============================] - 0s 306us/step - loss: 0.2454 - mse: 0.2454\n",
      "Epoch 98/100\n",
      "833/833 [==============================] - 0s 311us/step - loss: 0.2176 - mse: 0.2176\n",
      "Epoch 99/100\n",
      "833/833 [==============================] - 0s 304us/step - loss: 0.2173 - mse: 0.2173\n",
      "Epoch 100/100\n",
      "833/833 [==============================] - 0s 313us/step - loss: 0.2238 - mse: 0.2238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fb3225ac210>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Feature Scaling/preprocessing - normalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Building model\n",
    "model = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "model.add(Dense(8, activation = 'relu', input_dim = 40))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "model.add(Dense(units = 16, activation = 'relu'))\n",
    "\n",
    "#avoids overfitting\n",
    "#https://keras.io/api/layers/regularization_layers/dropout/\n",
    "model.add(keras.layers.Dropout(0.1))\n",
    "\n",
    "\n",
    "# Adding the output layer\n",
    "\n",
    "model.add(Dense(units = 1))\n",
    "\n",
    "\n",
    "# Compiling the ANN\n",
    "history=model.compile(optimizer = 'adam', loss = 'mse', metrics=['mse'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "model.fit(X_train, y_train, batch_size = 10, epochs = 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters involved:\n",
    "    https://keras.io/api/models/model_training_apis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209/209 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "#model evaluation\n",
    "mse = model.evaluate(X_test, y_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE without tuning: 6.286679267883301\n"
     ]
    }
   ],
   "source": [
    "print('MSE without tuning: {}'.format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 8)                 328       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 489\n",
      "Trainable params: 489\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://keras.io/api/models/sequential/\n",
    "The Sequential Class, provides a training and inference features on this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "plt.plot(y_test, color = 'red', label = 'Real data')\n",
    "plt.plot(y_pred, color = 'blue', label = 'Predicted data')\n",
    "plt.title('Prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cite: https://stackoverflow.com/questions/49008074/how-to-create-a-neural-network-for-regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.9404389101015778\n",
      "Mean Squared Error: 6.286678629045263\n",
      "Root Mean Squared Error: 2.507324994699583\n"
     ]
    }
   ],
   "source": [
    "#Why are my errors all of a sudden so because of overfitting?\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kerastuner'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-f94dd1d78b5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkerastuner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkerastuner\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHyperModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'kerastuner'"
     ]
    }
   ],
   "source": [
    "import kerastuner\n",
    "from kerastuner import HyperModel\n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(\n",
    "        units=hp.Int('units', min_value=8, max_value=32, step=4), \n",
    "        activation = hp.Choice('dense_activation', \n",
    "                values=['relu', 'tanh','sigmoid']),#,'softmax']),\n",
    "        input_dim = 40\n",
    "        )\n",
    "             \n",
    "    )\n",
    "\n",
    "    model.add(Dense(\n",
    "        units=hp.Int('units', min_value=8, max_value=32, step=4), \n",
    "        activation = hp.Choice('dense_activation', \n",
    "                values=['relu', 'tanh','sigmoid'])#,'softmax'])\n",
    "        )\n",
    "             \n",
    "    )\n",
    "    \n",
    "    model.add(\n",
    "        keras.layers.Dropout(\n",
    "            hp.Float(\n",
    "                    'dropout',\n",
    "                    min_value=0.0,\n",
    "                    max_value=0.1,\n",
    "                    step=0.01)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Adding the output layer\n",
    "    model.add(Dense(units = 1))\n",
    "\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        #optimizer = hp.Choice('dense_optimizer',\n",
    "                #values=['adam','SGD','rmsprop','adadelta'] ),\n",
    "        loss = 'mse',\n",
    "        metrics = ['mse']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_rs = kerastuner.tuners.RandomSearch(\n",
    "            build_model,\n",
    "            objective='mse',\n",
    "            max_trials=5,\n",
    "            executions_per_trial=2, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_rs.search(X_train, y_train, epochs=10) #, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_model = tuner_rs.get_best_models(num_models=1)\n",
    "best_model = tuner_rs.get_best_models(num_models=1)[0]\n",
    "mse_rs = best_model.evaluate(X_test, y_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, mse = best_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_rs.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
