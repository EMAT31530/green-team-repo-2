{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "conceptual-colon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graphic-level",
   "metadata": {},
   "source": [
    "### Pulling data from pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "regular-muslim",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>Food Group</th>\n",
       "      <th>Branded?</th>\n",
       "      <th>Price (£)</th>\n",
       "      <th>Weight (GRAMS)</th>\n",
       "      <th>Price per Weight (£/100Gram)</th>\n",
       "      <th>Carbon Group</th>\n",
       "      <th>Land use (m2/100g)</th>\n",
       "      <th>GHG(kgco2eq/100g)</th>\n",
       "      <th>Water use (L/100g)</th>\n",
       "      <th>Acidifying emissions(kgSO2eq/100g)</th>\n",
       "      <th>Eutr emissions  (kg PO43-eq per 100g)</th>\n",
       "      <th>Calories</th>\n",
       "      <th>Fat (g)</th>\n",
       "      <th>Protein (g)</th>\n",
       "      <th>Carbohydrate (g)</th>\n",
       "      <th>Sugars (g)</th>\n",
       "      <th>Fiber (g)</th>\n",
       "      <th>Cholesterol (mg)</th>\n",
       "      <th>Saturated Fats (g)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pillsbury Cinnamon Rolls With Icing Refrigerat...</td>\n",
       "      <td>Baked Foods</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.70</td>\n",
       "      <td>260.0</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>Bread products</td>\n",
       "      <td>0.3482</td>\n",
       "      <td>0.1441</td>\n",
       "      <td>56.7</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>330</td>\n",
       "      <td>11.27</td>\n",
       "      <td>4.34</td>\n",
       "      <td>53.42</td>\n",
       "      <td>21.34</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Waffles Buttermilk Frozen Ready-To-Heat</td>\n",
       "      <td>Baked Foods</td>\n",
       "      <td>X</td>\n",
       "      <td>1.50</td>\n",
       "      <td>567.0</td>\n",
       "      <td>0.264550</td>\n",
       "      <td>Bread products</td>\n",
       "      <td>0.3482</td>\n",
       "      <td>0.1441</td>\n",
       "      <td>56.7</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>273</td>\n",
       "      <td>9.22</td>\n",
       "      <td>6.58</td>\n",
       "      <td>41.05</td>\n",
       "      <td>4.30</td>\n",
       "      <td>2.2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Waffle Buttermilk Frozen Ready-To-Heat Toasted</td>\n",
       "      <td>Baked Foods</td>\n",
       "      <td>X</td>\n",
       "      <td>1.50</td>\n",
       "      <td>567.0</td>\n",
       "      <td>0.264550</td>\n",
       "      <td>Bread products</td>\n",
       "      <td>0.3482</td>\n",
       "      <td>0.1441</td>\n",
       "      <td>56.7</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>309</td>\n",
       "      <td>9.49</td>\n",
       "      <td>7.42</td>\n",
       "      <td>48.39</td>\n",
       "      <td>4.41</td>\n",
       "      <td>2.6</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Waffle Buttermilk Frozen Ready-To-Heat Microwaved</td>\n",
       "      <td>Baked Foods</td>\n",
       "      <td>X</td>\n",
       "      <td>1.50</td>\n",
       "      <td>567.0</td>\n",
       "      <td>0.264550</td>\n",
       "      <td>Bread products</td>\n",
       "      <td>0.3482</td>\n",
       "      <td>0.1441</td>\n",
       "      <td>56.7</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>289</td>\n",
       "      <td>9.40</td>\n",
       "      <td>6.92</td>\n",
       "      <td>44.16</td>\n",
       "      <td>4.50</td>\n",
       "      <td>2.4</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Waffle Plain Frozen Ready-To-Heat Microwave</td>\n",
       "      <td>Baked Foods</td>\n",
       "      <td>X</td>\n",
       "      <td>1.50</td>\n",
       "      <td>567.0</td>\n",
       "      <td>0.264550</td>\n",
       "      <td>Bread products</td>\n",
       "      <td>0.3482</td>\n",
       "      <td>0.1441</td>\n",
       "      <td>56.7</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>298</td>\n",
       "      <td>9.91</td>\n",
       "      <td>6.71</td>\n",
       "      <td>45.41</td>\n",
       "      <td>5.04</td>\n",
       "      <td>2.4</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>Plantain Fried</td>\n",
       "      <td>Vegetables</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.90</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.058824</td>\n",
       "      <td>Other vegetables</td>\n",
       "      <td>0.0310</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>241</td>\n",
       "      <td>10.16</td>\n",
       "      <td>1.66</td>\n",
       "      <td>40.60</td>\n",
       "      <td>19.10</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>Romaine Lettuce Raw</td>\n",
       "      <td>Vegetables</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>Other vegetables</td>\n",
       "      <td>0.0310</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>19</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.39</td>\n",
       "      <td>3.78</td>\n",
       "      <td>0.71</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>Palak Paneer</td>\n",
       "      <td>Vegetables</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.75</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>Cheese</td>\n",
       "      <td>8.0642</td>\n",
       "      <td>2.1240</td>\n",
       "      <td>473.5</td>\n",
       "      <td>0.014894</td>\n",
       "      <td>0.008875</td>\n",
       "      <td>96</td>\n",
       "      <td>6.84</td>\n",
       "      <td>5.23</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>Carrots Raw Salad</td>\n",
       "      <td>Vegetables</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.041000</td>\n",
       "      <td>Other vegetables</td>\n",
       "      <td>0.0310</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>208</td>\n",
       "      <td>15.70</td>\n",
       "      <td>1.22</td>\n",
       "      <td>17.17</td>\n",
       "      <td>11.23</td>\n",
       "      <td>2.3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>Corn on the cob</td>\n",
       "      <td>Vegetables</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.50</td>\n",
       "      <td>875.0</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>Other vegetables</td>\n",
       "      <td>0.0310</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>67</td>\n",
       "      <td>1.22</td>\n",
       "      <td>2.28</td>\n",
       "      <td>14.30</td>\n",
       "      <td>4.43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1223 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   name   Food Group Branded?  \\\n",
       "0     Pillsbury Cinnamon Rolls With Icing Refrigerat...  Baked Foods      NaN   \n",
       "1               Waffles Buttermilk Frozen Ready-To-Heat  Baked Foods        X   \n",
       "2        Waffle Buttermilk Frozen Ready-To-Heat Toasted  Baked Foods        X   \n",
       "3     Waffle Buttermilk Frozen Ready-To-Heat Microwaved  Baked Foods        X   \n",
       "4           Waffle Plain Frozen Ready-To-Heat Microwave  Baked Foods        X   \n",
       "...                                                 ...          ...      ...   \n",
       "1218                                    Plantain Fried    Vegetables      NaN   \n",
       "1219                                Romaine Lettuce Raw   Vegetables      NaN   \n",
       "1220                                       Palak Paneer   Vegetables      NaN   \n",
       "1221                                  Carrots Raw Salad   Vegetables      NaN   \n",
       "1222                                   Corn on the cob    Vegetables      NaN   \n",
       "\n",
       "      Price (£)  Weight (GRAMS)  Price per Weight (£/100Gram)  \\\n",
       "0          1.70           260.0                      0.653846   \n",
       "1          1.50           567.0                      0.264550   \n",
       "2          1.50           567.0                      0.264550   \n",
       "3          1.50           567.0                      0.264550   \n",
       "4          1.50           567.0                      0.264550   \n",
       "...         ...             ...                           ...   \n",
       "1218       0.90            85.0                      1.058824   \n",
       "1219       1.00           400.0                      0.250000   \n",
       "1220       3.75           500.0                      0.750000   \n",
       "1221       0.41          1000.0                      0.041000   \n",
       "1222       1.50           875.0                      0.171429   \n",
       "\n",
       "           Carbon Group  Land use (m2/100g)  GHG(kgco2eq/100g)  \\\n",
       "0       Bread products               0.3482             0.1441   \n",
       "1       Bread products               0.3482             0.1441   \n",
       "2       Bread products               0.3482             0.1441   \n",
       "3       Bread products               0.3482             0.1441   \n",
       "4       Bread products               0.3482             0.1441   \n",
       "...                 ...                 ...                ...   \n",
       "1218  Other vegetables               0.0310             0.0455   \n",
       "1219  Other vegetables               0.0310             0.0455   \n",
       "1220            Cheese               8.0642             2.1240   \n",
       "1221  Other vegetables               0.0310             0.0455   \n",
       "1222  Other vegetables               0.0310             0.0455   \n",
       "\n",
       "      Water use (L/100g)  Acidifying emissions(kgSO2eq/100g)  \\\n",
       "0                   56.7                            0.001209   \n",
       "1                   56.7                            0.001209   \n",
       "2                   56.7                            0.001209   \n",
       "3                   56.7                            0.001209   \n",
       "4                   56.7                            0.001209   \n",
       "...                  ...                                 ...   \n",
       "1218                 8.3                            0.000531   \n",
       "1219                 8.3                            0.000531   \n",
       "1220               473.5                            0.014894   \n",
       "1221                 8.3                            0.000531   \n",
       "1222                 8.3                            0.000531   \n",
       "\n",
       "      Eutr emissions  (kg PO43-eq per 100g)  Calories  Fat (g)  Protein (g)  \\\n",
       "0                                  0.000706       330    11.27         4.34   \n",
       "1                                  0.000706       273     9.22         6.58   \n",
       "2                                  0.000706       309     9.49         7.42   \n",
       "3                                  0.000706       289     9.40         6.92   \n",
       "4                                  0.000706       298     9.91         6.71   \n",
       "...                                     ...       ...      ...          ...   \n",
       "1218                               0.000186       241    10.16         1.66   \n",
       "1219                               0.000186        19     0.27         1.39   \n",
       "1220                               0.008875        96     6.84         5.23   \n",
       "1221                               0.000186       208    15.70         1.22   \n",
       "1222                               0.000186        67     1.22         2.28   \n",
       "\n",
       "      Carbohydrate (g)  Sugars (g)  Fiber (g)  Cholesterol (mg)  \\\n",
       "0                53.42       21.34        1.4               0.0   \n",
       "1                41.05        4.30        2.2              15.0   \n",
       "2                48.39        4.41        2.6              13.0   \n",
       "3                44.16        4.50        2.4              16.0   \n",
       "4                45.41        5.04        2.4              16.0   \n",
       "...                ...         ...        ...               ...   \n",
       "1218             40.60       19.10        2.9               0.0   \n",
       "1219              3.78        0.71        3.1               0.0   \n",
       "1220              4.32        1.89        1.2               7.0   \n",
       "1221             17.17       11.23        2.3               9.0   \n",
       "1222             14.30        4.43        2.0               0.0   \n",
       "\n",
       "      Saturated Fats (g)  \n",
       "0                  3.250  \n",
       "1                  1.898  \n",
       "2                  2.275  \n",
       "3                  2.057  \n",
       "4                  1.580  \n",
       "...                  ...  \n",
       "1218               1.507  \n",
       "1219               0.053  \n",
       "1220               1.486  \n",
       "1221               2.452  \n",
       "1222               0.244  \n",
       "\n",
       "[1223 rows x 20 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nutrition = pd.read_pickle(\"./nutrition_data_clean.pkl\")\n",
    "nutrition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "listed-supervision",
   "metadata": {},
   "source": [
    "### Removing nans from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "varying-queen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GHG(kgco2eq/100g)',\n",
       " 'Water use (L/100g)',\n",
       " 'Acidifying emissions(kgSO2eq/100g)',\n",
       " 'Eutr emissions  (kg PO43-eq per 100g)',\n",
       " 'Calories',\n",
       " 'Fat (g)',\n",
       " 'Protein (g)',\n",
       " 'Carbohydrate (g)',\n",
       " 'Sugars (g)',\n",
       " 'Fiber (g)',\n",
       " 'Cholesterol (mg)']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = list(nutrition.columns)\n",
    "useful = columns[8:19]\n",
    "# creating this list to drop NaNs because it can't be done directly in the .dropna function.\n",
    "useful"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "natural-lithuania",
   "metadata": {},
   "source": [
    "### Removing NaN only in the columns labelled \"useful\" in cell above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "interior-queue",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>Food Group</th>\n",
       "      <th>Branded?</th>\n",
       "      <th>Price (£)</th>\n",
       "      <th>Weight (GRAMS)</th>\n",
       "      <th>Price per Weight (£/100Gram)</th>\n",
       "      <th>Carbon Group</th>\n",
       "      <th>Land use (m2/100g)</th>\n",
       "      <th>GHG(kgco2eq/100g)</th>\n",
       "      <th>Water use (L/100g)</th>\n",
       "      <th>Acidifying emissions(kgSO2eq/100g)</th>\n",
       "      <th>Eutr emissions  (kg PO43-eq per 100g)</th>\n",
       "      <th>Calories</th>\n",
       "      <th>Fat (g)</th>\n",
       "      <th>Protein (g)</th>\n",
       "      <th>Carbohydrate (g)</th>\n",
       "      <th>Sugars (g)</th>\n",
       "      <th>Fiber (g)</th>\n",
       "      <th>Cholesterol (mg)</th>\n",
       "      <th>Saturated Fats (g)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pillsbury Cinnamon Rolls With Icing Refrigerat...</td>\n",
       "      <td>Baked Foods</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.70</td>\n",
       "      <td>260.0</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>Bread products</td>\n",
       "      <td>0.3482</td>\n",
       "      <td>0.1441</td>\n",
       "      <td>56.7</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>330</td>\n",
       "      <td>11.27</td>\n",
       "      <td>4.34</td>\n",
       "      <td>53.42</td>\n",
       "      <td>21.34</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Waffles Buttermilk Frozen Ready-To-Heat</td>\n",
       "      <td>Baked Foods</td>\n",
       "      <td>X</td>\n",
       "      <td>1.50</td>\n",
       "      <td>567.0</td>\n",
       "      <td>0.264550</td>\n",
       "      <td>Bread products</td>\n",
       "      <td>0.3482</td>\n",
       "      <td>0.1441</td>\n",
       "      <td>56.7</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>273</td>\n",
       "      <td>9.22</td>\n",
       "      <td>6.58</td>\n",
       "      <td>41.05</td>\n",
       "      <td>4.30</td>\n",
       "      <td>2.2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Waffle Buttermilk Frozen Ready-To-Heat Toasted</td>\n",
       "      <td>Baked Foods</td>\n",
       "      <td>X</td>\n",
       "      <td>1.50</td>\n",
       "      <td>567.0</td>\n",
       "      <td>0.264550</td>\n",
       "      <td>Bread products</td>\n",
       "      <td>0.3482</td>\n",
       "      <td>0.1441</td>\n",
       "      <td>56.7</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>309</td>\n",
       "      <td>9.49</td>\n",
       "      <td>7.42</td>\n",
       "      <td>48.39</td>\n",
       "      <td>4.41</td>\n",
       "      <td>2.6</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Waffle Buttermilk Frozen Ready-To-Heat Microwaved</td>\n",
       "      <td>Baked Foods</td>\n",
       "      <td>X</td>\n",
       "      <td>1.50</td>\n",
       "      <td>567.0</td>\n",
       "      <td>0.264550</td>\n",
       "      <td>Bread products</td>\n",
       "      <td>0.3482</td>\n",
       "      <td>0.1441</td>\n",
       "      <td>56.7</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>289</td>\n",
       "      <td>9.40</td>\n",
       "      <td>6.92</td>\n",
       "      <td>44.16</td>\n",
       "      <td>4.50</td>\n",
       "      <td>2.4</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Waffle Plain Frozen Ready-To-Heat Microwave</td>\n",
       "      <td>Baked Foods</td>\n",
       "      <td>X</td>\n",
       "      <td>1.50</td>\n",
       "      <td>567.0</td>\n",
       "      <td>0.264550</td>\n",
       "      <td>Bread products</td>\n",
       "      <td>0.3482</td>\n",
       "      <td>0.1441</td>\n",
       "      <td>56.7</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>298</td>\n",
       "      <td>9.91</td>\n",
       "      <td>6.71</td>\n",
       "      <td>45.41</td>\n",
       "      <td>5.04</td>\n",
       "      <td>2.4</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>Plantain Fried</td>\n",
       "      <td>Vegetables</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.90</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.058824</td>\n",
       "      <td>Other vegetables</td>\n",
       "      <td>0.0310</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>241</td>\n",
       "      <td>10.16</td>\n",
       "      <td>1.66</td>\n",
       "      <td>40.60</td>\n",
       "      <td>19.10</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>Romaine Lettuce Raw</td>\n",
       "      <td>Vegetables</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>Other vegetables</td>\n",
       "      <td>0.0310</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>19</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.39</td>\n",
       "      <td>3.78</td>\n",
       "      <td>0.71</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>Palak Paneer</td>\n",
       "      <td>Vegetables</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.75</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>Cheese</td>\n",
       "      <td>8.0642</td>\n",
       "      <td>2.1240</td>\n",
       "      <td>473.5</td>\n",
       "      <td>0.014894</td>\n",
       "      <td>0.008875</td>\n",
       "      <td>96</td>\n",
       "      <td>6.84</td>\n",
       "      <td>5.23</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>Carrots Raw Salad</td>\n",
       "      <td>Vegetables</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.041000</td>\n",
       "      <td>Other vegetables</td>\n",
       "      <td>0.0310</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>208</td>\n",
       "      <td>15.70</td>\n",
       "      <td>1.22</td>\n",
       "      <td>17.17</td>\n",
       "      <td>11.23</td>\n",
       "      <td>2.3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>Corn on the cob</td>\n",
       "      <td>Vegetables</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.50</td>\n",
       "      <td>875.0</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>Other vegetables</td>\n",
       "      <td>0.0310</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>67</td>\n",
       "      <td>1.22</td>\n",
       "      <td>2.28</td>\n",
       "      <td>14.30</td>\n",
       "      <td>4.43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1189 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   name   Food Group Branded?  \\\n",
       "0     Pillsbury Cinnamon Rolls With Icing Refrigerat...  Baked Foods      NaN   \n",
       "1               Waffles Buttermilk Frozen Ready-To-Heat  Baked Foods        X   \n",
       "2        Waffle Buttermilk Frozen Ready-To-Heat Toasted  Baked Foods        X   \n",
       "3     Waffle Buttermilk Frozen Ready-To-Heat Microwaved  Baked Foods        X   \n",
       "4           Waffle Plain Frozen Ready-To-Heat Microwave  Baked Foods        X   \n",
       "...                                                 ...          ...      ...   \n",
       "1218                                    Plantain Fried    Vegetables      NaN   \n",
       "1219                                Romaine Lettuce Raw   Vegetables      NaN   \n",
       "1220                                       Palak Paneer   Vegetables      NaN   \n",
       "1221                                  Carrots Raw Salad   Vegetables      NaN   \n",
       "1222                                   Corn on the cob    Vegetables      NaN   \n",
       "\n",
       "      Price (£)  Weight (GRAMS)  Price per Weight (£/100Gram)  \\\n",
       "0          1.70           260.0                      0.653846   \n",
       "1          1.50           567.0                      0.264550   \n",
       "2          1.50           567.0                      0.264550   \n",
       "3          1.50           567.0                      0.264550   \n",
       "4          1.50           567.0                      0.264550   \n",
       "...         ...             ...                           ...   \n",
       "1218       0.90            85.0                      1.058824   \n",
       "1219       1.00           400.0                      0.250000   \n",
       "1220       3.75           500.0                      0.750000   \n",
       "1221       0.41          1000.0                      0.041000   \n",
       "1222       1.50           875.0                      0.171429   \n",
       "\n",
       "           Carbon Group  Land use (m2/100g)  GHG(kgco2eq/100g)  \\\n",
       "0       Bread products               0.3482             0.1441   \n",
       "1       Bread products               0.3482             0.1441   \n",
       "2       Bread products               0.3482             0.1441   \n",
       "3       Bread products               0.3482             0.1441   \n",
       "4       Bread products               0.3482             0.1441   \n",
       "...                 ...                 ...                ...   \n",
       "1218  Other vegetables               0.0310             0.0455   \n",
       "1219  Other vegetables               0.0310             0.0455   \n",
       "1220            Cheese               8.0642             2.1240   \n",
       "1221  Other vegetables               0.0310             0.0455   \n",
       "1222  Other vegetables               0.0310             0.0455   \n",
       "\n",
       "      Water use (L/100g)  Acidifying emissions(kgSO2eq/100g)  \\\n",
       "0                   56.7                            0.001209   \n",
       "1                   56.7                            0.001209   \n",
       "2                   56.7                            0.001209   \n",
       "3                   56.7                            0.001209   \n",
       "4                   56.7                            0.001209   \n",
       "...                  ...                                 ...   \n",
       "1218                 8.3                            0.000531   \n",
       "1219                 8.3                            0.000531   \n",
       "1220               473.5                            0.014894   \n",
       "1221                 8.3                            0.000531   \n",
       "1222                 8.3                            0.000531   \n",
       "\n",
       "      Eutr emissions  (kg PO43-eq per 100g)  Calories  Fat (g)  Protein (g)  \\\n",
       "0                                  0.000706       330    11.27         4.34   \n",
       "1                                  0.000706       273     9.22         6.58   \n",
       "2                                  0.000706       309     9.49         7.42   \n",
       "3                                  0.000706       289     9.40         6.92   \n",
       "4                                  0.000706       298     9.91         6.71   \n",
       "...                                     ...       ...      ...          ...   \n",
       "1218                               0.000186       241    10.16         1.66   \n",
       "1219                               0.000186        19     0.27         1.39   \n",
       "1220                               0.008875        96     6.84         5.23   \n",
       "1221                               0.000186       208    15.70         1.22   \n",
       "1222                               0.000186        67     1.22         2.28   \n",
       "\n",
       "      Carbohydrate (g)  Sugars (g)  Fiber (g)  Cholesterol (mg)  \\\n",
       "0                53.42       21.34        1.4               0.0   \n",
       "1                41.05        4.30        2.2              15.0   \n",
       "2                48.39        4.41        2.6              13.0   \n",
       "3                44.16        4.50        2.4              16.0   \n",
       "4                45.41        5.04        2.4              16.0   \n",
       "...                ...         ...        ...               ...   \n",
       "1218             40.60       19.10        2.9               0.0   \n",
       "1219              3.78        0.71        3.1               0.0   \n",
       "1220              4.32        1.89        1.2               7.0   \n",
       "1221             17.17       11.23        2.3               9.0   \n",
       "1222             14.30        4.43        2.0               0.0   \n",
       "\n",
       "      Saturated Fats (g)  \n",
       "0                  3.250  \n",
       "1                  1.898  \n",
       "2                  2.275  \n",
       "3                  2.057  \n",
       "4                  1.580  \n",
       "...                  ...  \n",
       "1218               1.507  \n",
       "1219               0.053  \n",
       "1220               1.486  \n",
       "1221               2.452  \n",
       "1222               0.244  \n",
       "\n",
       "[1189 rows x 20 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nutrition = nutrition.dropna(subset=useful)\n",
    "nutrition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funky-blocking",
   "metadata": {},
   "source": [
    "### Extracting the nutrition data as the features, labelled X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "flush-petroleum",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acidifying emissions(kgSO2eq/100g)</th>\n",
       "      <th>Eutr emissions  (kg PO43-eq per 100g)</th>\n",
       "      <th>Calories</th>\n",
       "      <th>Fat (g)</th>\n",
       "      <th>Protein (g)</th>\n",
       "      <th>Carbohydrate (g)</th>\n",
       "      <th>Sugars (g)</th>\n",
       "      <th>Fiber (g)</th>\n",
       "      <th>Cholesterol (mg)</th>\n",
       "      <th>Saturated Fats (g)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001209</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>330</td>\n",
       "      <td>11.27</td>\n",
       "      <td>4.34</td>\n",
       "      <td>53.42</td>\n",
       "      <td>21.34</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001209</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>273</td>\n",
       "      <td>9.22</td>\n",
       "      <td>6.58</td>\n",
       "      <td>41.05</td>\n",
       "      <td>4.30</td>\n",
       "      <td>2.2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001209</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>309</td>\n",
       "      <td>9.49</td>\n",
       "      <td>7.42</td>\n",
       "      <td>48.39</td>\n",
       "      <td>4.41</td>\n",
       "      <td>2.6</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001209</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>289</td>\n",
       "      <td>9.40</td>\n",
       "      <td>6.92</td>\n",
       "      <td>44.16</td>\n",
       "      <td>4.50</td>\n",
       "      <td>2.4</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001209</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>298</td>\n",
       "      <td>9.91</td>\n",
       "      <td>6.71</td>\n",
       "      <td>45.41</td>\n",
       "      <td>5.04</td>\n",
       "      <td>2.4</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>241</td>\n",
       "      <td>10.16</td>\n",
       "      <td>1.66</td>\n",
       "      <td>40.60</td>\n",
       "      <td>19.10</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>19</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.39</td>\n",
       "      <td>3.78</td>\n",
       "      <td>0.71</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>0.014894</td>\n",
       "      <td>0.008875</td>\n",
       "      <td>96</td>\n",
       "      <td>6.84</td>\n",
       "      <td>5.23</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>208</td>\n",
       "      <td>15.70</td>\n",
       "      <td>1.22</td>\n",
       "      <td>17.17</td>\n",
       "      <td>11.23</td>\n",
       "      <td>2.3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>67</td>\n",
       "      <td>1.22</td>\n",
       "      <td>2.28</td>\n",
       "      <td>14.30</td>\n",
       "      <td>4.43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1189 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Acidifying emissions(kgSO2eq/100g)  \\\n",
       "0                               0.001209   \n",
       "1                               0.001209   \n",
       "2                               0.001209   \n",
       "3                               0.001209   \n",
       "4                               0.001209   \n",
       "...                                  ...   \n",
       "1218                            0.000531   \n",
       "1219                            0.000531   \n",
       "1220                            0.014894   \n",
       "1221                            0.000531   \n",
       "1222                            0.000531   \n",
       "\n",
       "      Eutr emissions  (kg PO43-eq per 100g)  Calories  Fat (g)  Protein (g)  \\\n",
       "0                                  0.000706       330    11.27         4.34   \n",
       "1                                  0.000706       273     9.22         6.58   \n",
       "2                                  0.000706       309     9.49         7.42   \n",
       "3                                  0.000706       289     9.40         6.92   \n",
       "4                                  0.000706       298     9.91         6.71   \n",
       "...                                     ...       ...      ...          ...   \n",
       "1218                               0.000186       241    10.16         1.66   \n",
       "1219                               0.000186        19     0.27         1.39   \n",
       "1220                               0.008875        96     6.84         5.23   \n",
       "1221                               0.000186       208    15.70         1.22   \n",
       "1222                               0.000186        67     1.22         2.28   \n",
       "\n",
       "      Carbohydrate (g)  Sugars (g)  Fiber (g)  Cholesterol (mg)  \\\n",
       "0                53.42       21.34        1.4               0.0   \n",
       "1                41.05        4.30        2.2              15.0   \n",
       "2                48.39        4.41        2.6              13.0   \n",
       "3                44.16        4.50        2.4              16.0   \n",
       "4                45.41        5.04        2.4              16.0   \n",
       "...                ...         ...        ...               ...   \n",
       "1218             40.60       19.10        2.9               0.0   \n",
       "1219              3.78        0.71        3.1               0.0   \n",
       "1220              4.32        1.89        1.2               7.0   \n",
       "1221             17.17       11.23        2.3               9.0   \n",
       "1222             14.30        4.43        2.0               0.0   \n",
       "\n",
       "      Saturated Fats (g)  \n",
       "0                  3.250  \n",
       "1                  1.898  \n",
       "2                  2.275  \n",
       "3                  2.057  \n",
       "4                  1.580  \n",
       "...                  ...  \n",
       "1218               1.507  \n",
       "1219               0.053  \n",
       "1220               1.486  \n",
       "1221               2.452  \n",
       "1222               0.244  \n",
       "\n",
       "[1189 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = nutrition.iloc[:,10:]\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-identification",
   "metadata": {},
   "source": [
    "### Extracting the GHG emissions, as the labels, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "removed-coalition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.1441\n",
       "1       0.1441\n",
       "2       0.1441\n",
       "3       0.1441\n",
       "4       0.1441\n",
       "         ...  \n",
       "1218    0.0455\n",
       "1219    0.0455\n",
       "1220    2.1240\n",
       "1221    0.0455\n",
       "1222    0.0455\n",
       "Name: GHG(kgco2eq/100g), Length: 1189, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = nutrition.iloc[:,8]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liquid-quality",
   "metadata": {},
   "source": [
    "### Test train splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "growing-platinum",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)\n",
    "# size is the size of the test dataset. size=0.2 means 80:20 test:train split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "leading-truck",
   "metadata": {},
   "source": [
    "#### adding a Validation set: X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "secure-kingston",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "legislative-attention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset: 665 --> 55.929% of whole dataset\n",
      "Size of validation dataset: 286 --> 24.054% of whole dataset\n",
      "Size of test dataset: 238 --> 20.017% of whole dataset\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "# Don't cheat - fit only on training data\n",
    "scaler.fit(X_train) \n",
    "X_train = scaler.transform(X_train)  \n",
    "# apply same transformation to test and validation datasets\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test) \n",
    "print('Size of train dataset:', len(X_train), '-->', (\"{:.3%}\".format((len(X_train)/len(X)))), 'of whole dataset')\n",
    "print('Size of validation dataset:', len(X_val), '-->', (\"{:.3%}\".format((len(X_val)/len(X)))), 'of whole dataset')\n",
    "print('Size of test dataset:', len(X_test), '-->', (\"{:.3%}\".format((len(X_test)/len(X)))), 'of whole dataset')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-rwanda",
   "metadata": {},
   "source": [
    "# Implementing the MLPRegressor from SKLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "metallic-discharge",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "regr = MLPRegressor(solver='adam', random_state=42, max_iter=1000).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "twenty-channels",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score was 0.9744156532232989\n"
     ]
    }
   ],
   "source": [
    "y_pred = regr.predict(X_test)\n",
    "score = regr.score(X_test, y_test)\n",
    "print('The score was', score)\n",
    "#print(regr.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structured-reception",
   "metadata": {},
   "source": [
    "### Mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "spare-iceland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean sq err = 0.07230218062067444\n",
      "Mean abs err = 0.1487825912812516\n",
      "Med abs err = 0.0692710053094182\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, median_absolute_error\n",
    "#from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "print('Mean sq err =', mean_squared_error(y_test, y_pred))\n",
    "print('Mean abs err =', mean_absolute_error(y_test, y_pred))\n",
    "print('Med abs err =', median_absolute_error(y_test, y_pred))\n",
    "#print('Med abs % err =', mean_absolute_percentage_error(y_test, y_pred))\n",
    "#print('Standard dev =', np.std(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "sophisticated-bumper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([1.77926302, 1.31358385, 2.42574215]),\n",
       " 'score_time': array([0.00391912, 0.003407  , 0.00967193]),\n",
       " 'test_score': array([-4.62970478, -2.04382796,  0.33681452])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cv_results = cross_validate(regr, X, y, cv=3)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "communist-basin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#from sklearn.svm import SVC\n",
    "#from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "raised-frost",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, axes=None, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate 3 plots: the test and training learning curve, the training\n",
    "    samples vs fit times curve, the fit times vs score curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : estimator instance\n",
    "        An estimator instance implementing `fit` and `predict` methods which\n",
    "        will be cloned for each validation.\n",
    "\n",
    "    title : str\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like of shape (n_samples, n_features)\n",
    "        Training vector, where ``n_samples`` is the number of samples and\n",
    "        ``n_features`` is the number of features.\n",
    "\n",
    "    y : array-like of shape (n_samples) or (n_samples, n_features)\n",
    "        Target relative to ``X`` for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    axes : array-like of shape (3,), default=None\n",
    "        Axes to use for plotting the curves.\n",
    "\n",
    "    ylim : tuple of shape (2,), default=None\n",
    "        Defines minimum and maximum y-values plotted, e.g. (ymin, ymax).\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, default=None\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "\n",
    "          - None, to use the default 5-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - :term:`CV splitter`,\n",
    "          - An iterable yielding (train, test) splits as arrays of indices.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : int or None, default=None\n",
    "        Number of jobs to run in parallel.\n",
    "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "        for more details.\n",
    "\n",
    "    train_sizes : array-like of shape (n_ticks,)\n",
    "        Relative or absolute numbers of training examples that will be used to\n",
    "        generate the learning curve. If the ``dtype`` is float, it is regarded\n",
    "        as a fraction of the maximum size of the training set (that is\n",
    "        determined by the selected validation method), i.e. it has to be within\n",
    "        (0, 1]. Otherwise it is interpreted as absolute sizes of the training\n",
    "        sets. Note that for classification the number of samples usually have\n",
    "        to be big enough to contain at least one sample from each class.\n",
    "        (default: np.linspace(0.1, 1.0, 5))\n",
    "    \"\"\"\n",
    "    if axes is None:\n",
    "        _, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "    axes[0].set_title(title)\n",
    "    if ylim is not None:\n",
    "        axes[0].set_ylim(*ylim)\n",
    "    axes[0].set_xlabel(\"Training examples\")\n",
    "    axes[0].set_ylabel(\"Score\")\n",
    "\n",
    "    train_sizes, train_scores, test_scores, fit_times, _ = \\\n",
    "        learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
    "                       train_sizes=train_sizes,\n",
    "                       return_times=True)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    fit_times_mean = np.mean(fit_times, axis=1)\n",
    "    fit_times_std = np.std(fit_times, axis=1)\n",
    "    \n",
    "    \n",
    "    # Plot learning curve\n",
    "    axes[0].grid()\n",
    "    axes[0].fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                         train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                         color=\"r\")\n",
    "    axes[0].fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.1,\n",
    "                         color=\"g\")\n",
    "    axes[0].plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "                 label=\"Training score\")\n",
    "    axes[0].plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "                 label=\"Cross-validation score\")\n",
    "    axes[0].legend(loc=\"best\")\n",
    "\n",
    "    # Plot n_samples vs fit_times\n",
    "    axes[1].grid()\n",
    "    axes[1].plot(train_sizes, fit_times_mean, 'o-')\n",
    "    axes[1].fill_between(train_sizes, fit_times_mean - fit_times_std,\n",
    "                         fit_times_mean + fit_times_std, alpha=0.1)\n",
    "    axes[1].set_xlabel(\"Training examples\")\n",
    "    axes[1].set_ylabel(\"fit_times\")\n",
    "    axes[1].set_title(\"Scalability of the model\")\n",
    "\n",
    "    # Plot fit_time vs score\n",
    "    axes[2].grid()\n",
    "    axes[2].plot(fit_times_mean, test_scores_mean, 'o-')\n",
    "    axes[2].fill_between(fit_times_mean, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.1)\n",
    "    axes[2].set_xlabel(\"fit_times\")\n",
    "    axes[2].set_ylabel(\"Score\")\n",
    "    axes[2].set_title(\"Performance of the model\")\n",
    "\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "molecular-opera",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-eaf0159b6fb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m plot_learning_curve(estimator, title, X, y, axes=axes[:, 0], ylim=(0.7, 1.01),\n\u001b[0;32m---> 14\u001b[0;31m                     cv=cv, n_jobs=4)\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Learning Curve 2\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-0ba1e6cd3a59>\u001b[0m in \u001b[0;36mplot_learning_curve\u001b[0;34m(estimator, title, X, y, axes, ylim, cv, n_jobs, train_sizes)\u001b[0m\n\u001b[1;32m     74\u001b[0m         learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n\u001b[1;32m     75\u001b[0m                        \u001b[0mtrain_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_sizes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                        return_times=True)\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0mtrain_scores_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mtrain_scores_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mlearning_curve\u001b[0;34m(estimator, X, y, groups, train_sizes, cv, scoring, exploit_incremental_learning, n_jobs, pre_dispatch, verbose, shuffle, random_state, error_score, return_times, fit_params)\u001b[0m\n\u001b[1;32m   1398\u001b[0m             \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1399\u001b[0m             error_score=error_score, return_times=return_times)\n\u001b[0;32m-> 1400\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_test_proportions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1401\u001b[0m         )\n\u001b[1;32m   1402\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_aggregate_score_dicts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    953\u001b[0m                     \u001b[0;31m# scheduling.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    956\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mabort_everything\u001b[0;34m(self, ensure_ready)\u001b[0m\n\u001b[1;32m    559\u001b[0m         \"\"\"Shutdown the workers and restart a new one with the same parameters\n\u001b[1;32m    560\u001b[0m         \"\"\"\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkill_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/executor.py\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self, kill_workers)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkill_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkill_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkill_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkill_workers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;31m# When workers are killed in such a brutal manner, they cannot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self, wait, kill_workers)\u001b[0m\n\u001b[1;32m   1169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexecutor_manager_thread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m             \u001b[0mexecutor_manager_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         \u001b[0;31m# To reduce the risk of opening too many files, remove references to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1080 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(3, 2, figsize=(10, 15))\n",
    "\n",
    "#X, y = load_digits(return_X_y=True)\n",
    "\n",
    "title = \"Learning Curve - MPL\"\n",
    "# Cross validation with 100 iterations to get smoother mean test and train\n",
    "# score curves, each time with 20% data randomly selected as a validation set.\n",
    "cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\n",
    "\n",
    "regr = MLPRegressor(solver='adam', random_state=0, max_iter=1000).fit(X_train, y_train)\n",
    "estimator = regr\n",
    "\n",
    "plot_learning_curve(estimator, title, X, y, axes=axes[:, 0], ylim=(0.7, 1.01),\n",
    "                    cv=cv, n_jobs=4)\n",
    "\n",
    "title = \"Learning Curve 2\"\n",
    "# SVC is more expensive so we do a lower number of CV iterations:\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "estimator = MLPRegressor(solver='adam', random_state=42, max_iter=1000).fit(X_train, y_train)\n",
    "plot_learning_curve(estimator, title, X, y, axes=axes[:, 1], ylim=(0.7, 1.01),\n",
    "                    cv=cv, n_jobs=4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convenient-creature",
   "metadata": {},
   "source": [
    "# Learning and validation curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-playing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.naive_bayes import GaussianNB\n",
    "#from sklearn.svm import SVC\n",
    "#from sklearn.datasets import load_digits\n",
    "from skopt import BayesSearchCV \n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upset-trunk",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, axes=None, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=len(X_train)):\n",
    "    if axes is None:\n",
    "        _, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "    axes[0].set_title(title)\n",
    "    if ylim is not None:\n",
    "        axes[0].set_ylim(*ylim)\n",
    "    axes[0].set_xlabel(\"Training examples\")\n",
    "    axes[0].set_ylabel(\"Score\")\n",
    "\n",
    "    train_sizes, train_scores, test_scores, fit_times, _ = learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs, \n",
    "                                                                          train_sizes=train_sizes, return_times=True)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    fit_times_mean = np.mean(fit_times, axis=1)\n",
    "    fit_times_std = np.std(fit_times, axis=1)    \n",
    "\n",
    "    # Plot learning curve\n",
    "    axes[0].grid()\n",
    "    axes[0].fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                         train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                         color=\"r\")\n",
    "    axes[0].fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.1,\n",
    "                         color=\"g\")\n",
    "    axes[0].plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "                 label=\"Training score\")\n",
    "    axes[0].plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "                 label=\"Cross-validation score\")\n",
    "    axes[0].legend(loc=\"best\")\n",
    "\n",
    "    # Plot n_samples vs fit_times\n",
    "    axes[1].grid()\n",
    "    axes[1].plot(train_sizes, fit_times_mean, 'o-')\n",
    "    axes[1].fill_between(train_sizes, fit_times_mean - fit_times_std,\n",
    "                         fit_times_mean + fit_times_std, alpha=0.1)\n",
    "    axes[1].set_xlabel(\"Training examples\")\n",
    "    axes[1].set_ylabel(\"fit_times\")\n",
    "    axes[1].set_title(\"Scalability of the model\")\n",
    "\n",
    "    # Plot fit_time vs score\n",
    "    axes[2].grid()\n",
    "    axes[2].plot(fit_times_mean, test_scores_mean, 'o-')\n",
    "    axes[2].fill_between(fit_times_mean, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.1)\n",
    "    axes[2].set_xlabel(\"fit_times\")\n",
    "    axes[2].set_ylabel(\"Score\")\n",
    "    axes[2].set_title(\"Performance of the model\")\n",
    "\n",
    "    return plt\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(10, 15))\n",
    "\n",
    "X, y = (X_train, y_train)\n",
    "\n",
    "title = \"Learning Curve\"\n",
    "# Cross validation with 100 iterations to get smoother mean test and train\n",
    "# score curves, each time with 20% data randomly selected as a validation set.\n",
    "cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\n",
    "estimator = regr\n",
    "plot_learning_curve(estimator, title, X, y, axes=axes[:, 0], ylim=(0.7, 1.01))\n",
    "\n",
    "title = r\"Learning Curves (SVM, RBF kernel, $\\gamma=0.001$)\"\n",
    "# SVC is more expensive so we do a lower number of CV iterations:\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "estimator = SVC(gamma=0.001)\n",
    "plot_learning_curve(estimator, title, X, y, axes=axes[:, 1], ylim=(0.7, 1.01),\n",
    "                    n_jobs=4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-translator",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
