{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from keras.losses import mean_squared_error\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull dataset\n",
    "nutrition = pd.read_pickle(\"./Nutrition_Full_Features.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop rows with NaN\n",
    "nutrition = nutrition.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data for features\n",
    "X_original = nutrition.iloc[:, 11:]\n",
    "y = nutrition.iloc[:, 7]\n",
    "y = y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise the data by feature column\n",
    "X = preprocessing.normalize(X_original, axis=0)\n",
    "X = pd.DataFrame(X_original, columns = X_original.columns) # processing loses columns headers so these must be reestablished\n",
    "X = X.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "84/84 [==============================] - 1s 2ms/step - loss: 461784.3911 - accuracy: 0.0041\n",
      "Epoch 2/100\n",
      "84/84 [==============================] - 0s 997us/step - loss: 140795.6934 - accuracy: 3.8802e-04\n",
      "Epoch 3/100\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 60131.8918 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 32169.8006 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 39632.4109 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "84/84 [==============================] - 0s 997us/step - loss: 32562.2803 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "84/84 [==============================] - 0s 973us/step - loss: 26444.2024 - accuracy: 2.9606e-04: 0s - loss: 26640.9823 - accuracy: 0.0000e+0\n",
      "Epoch 8/100\n",
      "84/84 [==============================] - 0s 937us/step - loss: 28106.5534 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "84/84 [==============================] - 0s 896us/step - loss: 19740.8975 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "84/84 [==============================] - 0s 869us/step - loss: 12825.7282 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "84/84 [==============================] - 0s 889us/step - loss: 21564.7146 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "84/84 [==============================] - 0s 997us/step - loss: 39746.5177 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "84/84 [==============================] - 0s 901us/step - loss: 8203.4947 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "84/84 [==============================] - 0s 877us/step - loss: 8798.8129 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "84/84 [==============================] - 0s 949us/step - loss: 8399.5985 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "84/84 [==============================] - 0s 829us/step - loss: 5566.7667 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "84/84 [==============================] - 0s 889us/step - loss: 4187.0120 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "84/84 [==============================] - 0s 889us/step - loss: 4162.1305 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 5140.0934 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "84/84 [==============================] - 0s 913us/step - loss: 3932.0405 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 5611.6819 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "84/84 [==============================] - 0s 889us/step - loss: 3656.3186 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "84/84 [==============================] - 0s 913us/step - loss: 2986.3197 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 1969.0167 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "84/84 [==============================] - 0s 877us/step - loss: 1854.5074 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "84/84 [==============================] - 0s 887us/step - loss: 1650.3858 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "84/84 [==============================] - 0s 924us/step - loss: 3595.7720 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "84/84 [==============================] - 0s 889us/step - loss: 1914.6028 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "84/84 [==============================] - 0s 985us/step - loss: 1048.0153 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "84/84 [==============================] - 0s 901us/step - loss: 1581.2866 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "84/84 [==============================] - 0s 853us/step - loss: 2559.7287 - accuracy: 0.0019\n",
      "Epoch 32/100\n",
      "84/84 [==============================] - 0s 961us/step - loss: 1964.9745 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "84/84 [==============================] - 0s 974us/step - loss: 1336.2338 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "84/84 [==============================] - 0s 973us/step - loss: 1356.3709 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "84/84 [==============================] - 0s 961us/step - loss: 583.8033 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "84/84 [==============================] - 0s 967us/step - loss: 704.8090 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "84/84 [==============================] - 0s 973us/step - loss: 615.3851 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "84/84 [==============================] - 0s 925us/step - loss: 1375.3192 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "84/84 [==============================] - 0s 865us/step - loss: 1994.0038 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "84/84 [==============================] - 0s 841us/step - loss: 589.4893 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "84/84 [==============================] - 0s 925us/step - loss: 1251.5217 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "84/84 [==============================] - 0s 908us/step - loss: 1126.6302 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "84/84 [==============================] - 0s 961us/step - loss: 604.2801 - accuracy: 2.2734e-04\n",
      "Epoch 44/100\n",
      "84/84 [==============================] - 0s 889us/step - loss: 434.3361 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "84/84 [==============================] - 0s 853us/step - loss: 1282.5350 - accuracy: 1.4673e-04\n",
      "Epoch 46/100\n",
      "84/84 [==============================] - 0s 913us/step - loss: 475.8054 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "84/84 [==============================] - 0s 877us/step - loss: 730.6418 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "84/84 [==============================] - 0s 913us/step - loss: 494.5689 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "84/84 [==============================] - 0s 889us/step - loss: 253.7663 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "84/84 [==============================] - 0s 877us/step - loss: 282.7740 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "84/84 [==============================] - 0s 859us/step - loss: 559.2108 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "84/84 [==============================] - 0s 865us/step - loss: 208.3882 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "84/84 [==============================] - 0s 961us/step - loss: 529.1029 - accuracy: 1.0089e-04\n",
      "Epoch 54/100\n",
      "84/84 [==============================] - 0s 949us/step - loss: 243.6884 - accuracy: 8.5076e-04\n",
      "Epoch 55/100\n",
      "84/84 [==============================] - 0s 937us/step - loss: 484.5688 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "84/84 [==============================] - 0s 889us/step - loss: 279.7789 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "84/84 [==============================] - 0s 853us/step - loss: 3147.6457 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "84/84 [==============================] - 0s 877us/step - loss: 645.5308 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "84/84 [==============================] - 0s 913us/step - loss: 55.1282 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "84/84 [==============================] - 0s 937us/step - loss: 145.0151 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "84/84 [==============================] - 0s 896us/step - loss: 391.8659 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "84/84 [==============================] - 0s 877us/step - loss: 289.3523 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "84/84 [==============================] - 0s 901us/step - loss: 128.7833 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "84/84 [==============================] - 0s 973us/step - loss: 253.1452 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "84/84 [==============================] - 0s 969us/step - loss: 31.3478 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "84/84 [==============================] - 0s 955us/step - loss: 121.7350 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "84/84 [==============================] - 0s 901us/step - loss: 75.8158 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "84/84 [==============================] - 0s 889us/step - loss: 52.3338 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "84/84 [==============================] - 0s 877us/step - loss: 25.4855 - accuracy: 0.0017\n",
      "Epoch 70/100\n",
      "84/84 [==============================] - 0s 889us/step - loss: 35.0682 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "84/84 [==============================] - 0s 865us/step - loss: 31.2996 - accuracy: 2.7850e-04\n",
      "Epoch 72/100\n",
      "84/84 [==============================] - 0s 949us/step - loss: 67.3760 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "84/84 [==============================] - 0s 877us/step - loss: 122.9128 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "84/84 [==============================] - 0s 853us/step - loss: 131.8898 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "84/84 [==============================] - 0s 937us/step - loss: 83.4474 - accuracy: 7.6865e-04\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 1ms/step - loss: 92.4067 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "84/84 [==============================] - 0s 961us/step - loss: 30.2192 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 75.5685 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 52.9046 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "84/84 [==============================] - 0s 973us/step - loss: 17.7010 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 17.3360 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "84/84 [==============================] - 0s 963us/step - loss: 16.1598 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 46.9377 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 28.4350 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "84/84 [==============================] - 0s 987us/step - loss: 31.1739 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "84/84 [==============================] - 0s 997us/step - loss: 56.3063 - accuracy: 0.0015\n",
      "Epoch 87/100\n",
      "84/84 [==============================] - 0s 997us/step - loss: 25.5316 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 11.1084 - accuracy: 5.6768e-05\n",
      "Epoch 89/100\n",
      "84/84 [==============================] - 0s 925us/step - loss: 6.1571 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 55.1394 - accuracy: 4.2421e-05\n",
      "Epoch 91/100\n",
      "84/84 [==============================] - 0s 913us/step - loss: 5.9244 - accuracy: 1.1597e-04\n",
      "Epoch 92/100\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 13.8025 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "84/84 [==============================] - 0s 985us/step - loss: 20.2498 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "84/84 [==============================] - 0s 961us/step - loss: 14.6656 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 6.8958 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 8.4994 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "84/84 [==============================] - 0s 853us/step - loss: 5.9540 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "84/84 [==============================] - 0s 937us/step - loss: 5.1449 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "84/84 [==============================] - 0s 877us/step - loss: 103.4150 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "84/84 [==============================] - 0s 853us/step - loss: 8.1939 - accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "#building keras Neural Network model\n",
    "\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential\n",
    "from keras import losses\n",
    "\n",
    "# model type\n",
    "model = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "model.add(Dense(8, activation = 'relu', input_dim = 40))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "model.add(Dense(units = 16, activation = 'relu'))\n",
    "\n",
    "# Could create for loop to check number of layers\n",
    "\n",
    "#avoids overfitting\n",
    "#https://keras.io/api/layers/regularization_layers/dropout/\n",
    "model.add(keras.layers.Dropout(0.1))\n",
    "\n",
    "\n",
    "# Adding the output layer\n",
    "model.add(Dense(units = 1))\n",
    "\n",
    "\n",
    "# Compiling the ANN\n",
    "model.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics=['accuracy'])#=history\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "history = model.fit(X_train, y_train, batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 9.15984058380127 / Test accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "#model evaluation\n",
    "score = model.evaluate(X_test, y_test, verbose = 0)\n",
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8)                 328       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 489\n",
      "Trainable params: 489\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores without tuning: [9.15984058380127, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print('Scores without tuning: {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predicted values\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot predicted values against test values\n",
    "plt.plot(y_test, color = 'red', label = 'Real data')\n",
    "plt.plot(y_pred, color = 'blue', label = 'Predicted data')\n",
    "plt.title('Prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 1.4077091019936157\n",
      "Mean Squared Error: 9.159841545650027\n",
      "Root Mean Squared Error: 3.026523012575656\n"
     ]
    }
   ],
   "source": [
    "# checking the output metrics\n",
    "from sklearn import metrics\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Standard Deviation: 1.6110865075846403\n",
      "Output Mean: 0.8464732245681383\n"
     ]
    }
   ],
   "source": [
    "y_mean = np.mean(y)\n",
    "y_std = np.std(y)\n",
    "print('Output Standard Deviation:', y_std)\n",
    "print('Output Mean:', y_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameter Tuning Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kerastuner\n",
    "from kerastuner import HyperModel\n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(\n",
    "        units=hp.Int('units', min_value=8, max_value=64, step=4), \n",
    "        activation = hp.Choice('dense_activation', \n",
    "                values=['relu', 'tanh','sigmoid','softmax']),\n",
    "        input_dim = 40\n",
    "        )\n",
    "             \n",
    "    )\n",
    "\n",
    "    model.add(Dense(\n",
    "        units=hp.Int('units', min_value=8, max_value=64, step=4), \n",
    "        activation = hp.Choice('dense_activation', \n",
    "                values=['relu', 'tanh','sigmoid','softmax'])\n",
    "        )\n",
    "             \n",
    "    )\n",
    "    \n",
    "    model.add(\n",
    "        keras.layers.Dropout(\n",
    "            hp.Float(\n",
    "                    'dropout',\n",
    "                    min_value=0.0,\n",
    "                    max_value=0.1,\n",
    "                    step=0.01)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Adding the output layer\n",
    "    model.add(Dense(units = 1))\n",
    "\n",
    "\n",
    "    model.compile(\n",
    "        optimizer = hp.Choice('dense_optimizer',\n",
    "                values=['adam','SGD','rmsprop','adadelta'] ),\n",
    "        loss = 'mean_squared_error',\n",
    "        metrics = ['accuracy'],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kerastuner.tuners.RandomSearch(\n",
    "            build_model,\n",
    "            objective='accuracy',\n",
    "            max_trials=200,\n",
    "            executions_per_trial=2,\n",
    "            project_name='hp_values',\n",
    "            overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 180 Complete [00h 00m 04s]\n",
      "accuracy: 0.0006002400768920779\n",
      "\n",
      "Best accuracy So Far: 0.0012004801537841558\n",
      "Total elapsed time: 00h 12m 18s\n",
      "\n",
      "Search: Running Trial #181\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "units             |32                |24                \n",
      "dense_activation  |sigmoid           |softmax           \n",
      "dropout           |0.09              |0.02              \n",
      "dense_optimizer   |SGD               |SGD               \n",
      "\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 1s 3ms/step - loss: 2.2086 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 2.3581 - accuracy: 0.0010\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 2.0544 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 2.2411 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 2.0103 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 2.2407 - accuracy: 5.4877e-04\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 2.1558 - accuracy: 1.7332e-04\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 1.9695 - accuracy: 0.0023\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 2.0023 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 2.2418 - accuracy: 3.7222e-04\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 1s 3ms/step - loss: 2.7104 - accuracy: 0.0021\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 2.5973 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 2.4165 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "23/27 [========================>.....] - ETA: 0s - loss: 2.5814 - accuracy: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-c528bc831cea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtuner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\kerastuner\\engine\\base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\kerastuner\\engine\\multi_execution_tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m             \u001b[0mcopied_fit_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'callbacks'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopied_fit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_values\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirection\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'min'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\kerastuner\\engine\\tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[1;34m(self, trial, fit_args, fit_kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m         \"\"\"\n\u001b[0;32m    140\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrun_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect best hyperparameters to rebuild model\n",
    "best_hp = tuner.get_best_hyperparameters()[0]\n",
    "model = tuner.hypermodel.build(best_hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get new predicted values with Hyperparameters\n",
    "y_hp_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot predicted values against test values\n",
    "plt.plot(y_test, color = 'red', label = 'Real data')\n",
    "plt.plot(y_hp_pred, color = 'blue', label = 'HP Predicted data')\n",
    "plt.title('HP Prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the output metrics\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_hp_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_hp_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_hp_pred)))\n",
    "\n",
    "y_mean = np.mean(y_hp_pred)\n",
    "y_std = np.std(y_hp_pred)\n",
    "print('Output Standard Deviation:', y_std)\n",
    "print('Output Mean:', y_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
